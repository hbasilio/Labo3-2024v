{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8136612f-162e-46f0-a44a-24248bd68ee1",
     "showTitle": false,
     "title": ""
    },
    "id": "92f70472-e7c5-4172-a8c8-85609c087247"
   },
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "\n",
    "# Lee el archivo como un DataFrame\n",
    "#df_ventas = pd.read_csv('/Users/micaelabassan/Desktop/fundamentos/Labo 3/sell-in.txt', delimiter='\\t',  decimal='.')  # Cambia el delimitador si es necesario\n",
    "#df_predict = pd.read_csv('/Users/micaelabassan/Desktop/fundamentos/Labo 3/productos_a_predecir.txt', delimiter='\\t')  # Cambia el delimitador si es necesario\n",
    "#df_product = pd.read_csv('/Users/micaelabassan/Desktop/fundamentos/Labo 3/tb_productoscorregida.txt', delimiter='\\t')  # Cambia el delimitador si es necesario\n",
    "#df_stocks = pd.read_csv('/Users/micaelabassan/Desktop/fundamentos/Labo 3/tb_stocks.txt', delimiter='\\t')  # Cambia el delimitador si es necesario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b90ea005-02dc-4807-bf87-c0dff6e144dc",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YzXOInmNGsoR",
    "outputId": "360a2bfb-0ae0-4e92-d9f1-99c633cf96a3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Montar Google Drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c85aaf81-9847-4e04-a0a0-2ea31258782c",
     "showTitle": false,
     "title": ""
    },
    "id": "6GY7G7zPHrud"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Leer el archivo CSV con pandas\n",
    "df_ventas = pd.read_csv('data/sell-in.txt', delimiter='\\t',  decimal='.')  # Cambia el delimitador si es necesario\n",
    "df_predict = pd.read_csv('data/productos_a_predecir.txt', delimiter='\\t')  # Cambia el delimitador si es necesario\n",
    "#df_product = pd.read_csv('data/tb_productoscorregida.txt', delimiter='\\t')  # Cambia el delimitador si es necesario\n",
    "df_stocks = pd.read_csv('data/tb_stocks.txt', delimiter='\\t')  # Cambia el delimitador si es necesario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e80f919-9a09-40fb-9010-45c785fc346d",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8373aa3-3e24-4d3d-8968-ec320ffdc46e",
    "outputId": "5c50fd14-2e1d-420e-fd35-53b19ae466ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   periodo  customer_id  product_id  plan_precios_cuidados  cust_request_qty  \\\n",
      "0   201701        10234       20524                      0                 2   \n",
      "1   201701        10032       20524                      0                 1   \n",
      "2   201701        10217       20524                      0                 1   \n",
      "3   201701        10125       20524                      0                 1   \n",
      "4   201701        10012       20524                      0                11   \n",
      "\n",
      "   cust_request_tn       tn  \n",
      "0          0.05300  0.05300  \n",
      "1          0.13628  0.13628  \n",
      "2          0.03028  0.03028  \n",
      "3          0.02271  0.02271  \n",
      "4          1.54452  1.54452  \n",
      "   periodo  product_id  stock_final\n",
      "0   201810       20524      1.61267\n",
      "1   201810       20311      2.93657\n",
      "2   201810       20654      6.83269\n",
      "3   201810       21005      1.01338\n",
      "4   201810       20974      0.34595\n",
      "   product_id\n",
      "0       20001\n",
      "1       20002\n",
      "2       20003\n",
      "3       20004\n",
      "4       20005\n"
     ]
    }
   ],
   "source": [
    "print(df_ventas.head())\n",
    "print(df_stocks.head())\n",
    "print(df_predict.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c4ba8c9-df60-415c-b308-9e000763b1fa",
     "showTitle": false,
     "title": ""
    },
    "id": "7f8f5b40-66cb-4cb3-bb2e-f80bc5ebd5a2"
   },
   "outputs": [],
   "source": [
    "df_ventas.periodo = pd.to_datetime(df_ventas.periodo, format='%Y%m')\n",
    "# Convertir 'periodo' a formato de fecha\n",
    "#data['periodo'] = pd.to_datetime(data['periodo'], format='%Y%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6325edc3-101f-41a8-b5b8-2f750dac3b87",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "031de60c-6300-49ce-8313-12a7d88f0db7",
    "outputId": "ec60c1af-7eee-4005-8f7f-e0704f43e4fd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10234</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.05300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10032</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>0.13628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10217</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>0.03028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10125</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>0.02271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10012</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>1.54452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     periodo  customer_id  product_id  plan_precios_cuidados  \\\n",
       "0 2017-01-01        10234       20524                      0   \n",
       "1 2017-01-01        10032       20524                      0   \n",
       "2 2017-01-01        10217       20524                      0   \n",
       "3 2017-01-01        10125       20524                      0   \n",
       "4 2017-01-01        10012       20524                      0   \n",
       "\n",
       "   cust_request_qty  cust_request_tn       tn  \n",
       "0                 2          0.05300  0.05300  \n",
       "1                 1          0.13628  0.13628  \n",
       "2                 1          0.03028  0.03028  \n",
       "3                 1          0.02271  0.02271  \n",
       "4                11          1.54452  1.54452  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ventas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f227721e-3494-4b72-9bbb-f8f623de6451",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10234</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.05300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10032</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>0.13628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10217</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>0.03028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10125</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>0.02271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10012</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>1.54452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945813</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10105</td>\n",
       "      <td>20853</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02230</td>\n",
       "      <td>0.02230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945814</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10092</td>\n",
       "      <td>20853</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00669</td>\n",
       "      <td>0.00669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945815</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10006</td>\n",
       "      <td>20853</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.02898</td>\n",
       "      <td>0.02898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945816</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10018</td>\n",
       "      <td>20853</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>0.01561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945817</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>10020</td>\n",
       "      <td>20853</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>0.01561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2945818 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           periodo  customer_id  product_id  plan_precios_cuidados  \\\n",
       "0       2017-01-01        10234       20524                      0   \n",
       "1       2017-01-01        10032       20524                      0   \n",
       "2       2017-01-01        10217       20524                      0   \n",
       "3       2017-01-01        10125       20524                      0   \n",
       "4       2017-01-01        10012       20524                      0   \n",
       "...            ...          ...         ...                    ...   \n",
       "2945813 2019-12-01        10105       20853                      0   \n",
       "2945814 2019-12-01        10092       20853                      0   \n",
       "2945815 2019-12-01        10006       20853                      0   \n",
       "2945816 2019-12-01        10018       20853                      0   \n",
       "2945817 2019-12-01        10020       20853                      0   \n",
       "\n",
       "         cust_request_qty  cust_request_tn       tn  \n",
       "0                       2          0.05300  0.05300  \n",
       "1                       1          0.13628  0.13628  \n",
       "2                       1          0.03028  0.03028  \n",
       "3                       1          0.02271  0.02271  \n",
       "4                      11          1.54452  1.54452  \n",
       "...                   ...              ...      ...  \n",
       "2945813                 1          0.02230  0.02230  \n",
       "2945814                 1          0.00669  0.00669  \n",
       "2945815                 7          0.02898  0.02898  \n",
       "2945816                 4          0.01561  0.01561  \n",
       "2945817                 2          0.01561  0.01561  \n",
       "\n",
       "[2945818 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4071007d-34ee-4e2d-bdb6-83595c9c1688",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestra del dataset:\n",
      "     periodo  customer_id  product_id  plan_precios_cuidados  \\\n",
      "0 2017-01-01        10234       20524                      0   \n",
      "1 2017-01-01        10032       20524                      0   \n",
      "2 2017-01-01        10217       20524                      0   \n",
      "3 2017-01-01        10125       20524                      0   \n",
      "4 2017-01-01        10012       20524                      0   \n",
      "\n",
      "   cust_request_qty  cust_request_tn       tn  \n",
      "0                 2          0.05300  0.05300  \n",
      "1                 1          0.13628  0.13628  \n",
      "2                 1          0.03028  0.03028  \n",
      "3                 1          0.02271  0.02271  \n",
      "4                11          1.54452  1.54452  \n",
      "\n",
      "Tipos de datos de cada columna:\n",
      "periodo                  datetime64[ns]\n",
      "customer_id                       int64\n",
      "product_id                        int64\n",
      "plan_precios_cuidados             int64\n",
      "cust_request_qty                  int64\n",
      "cust_request_tn                 float64\n",
      "tn                              float64\n",
      "dtype: object\n",
      "\n",
      "Valores únicos en la columna 'product_id':\n",
      "[20524 20311 20654 ... 20792 20854 20770]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hbasilio\\AppData\\Local\\Temp\\ipykernel_11176\\4128241735.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtrado['periodo'] = pd.to_datetime(df_filtrado['periodo'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supongamos que df_ventas es tu dataset\n",
    "# df_ventas = pd.read_csv('ruta_a_tu_dataset.csv')\n",
    "\n",
    "# Mostrar una muestra del dataset\n",
    "print(\"Muestra del dataset:\")\n",
    "print(df_ventas.head())\n",
    "\n",
    "# Mostrar los tipos de datos de cada columna\n",
    "print(\"\\nTipos de datos de cada columna:\")\n",
    "print(df_ventas.dtypes)\n",
    "\n",
    "# Mostrar los valores únicos en la columna 'product_id'\n",
    "print(\"\\nValores únicos en la columna 'product_id':\")\n",
    "print(df_ventas['product_id'].unique())\n",
    "\n",
    "# Filtrar el dataset por el product_id deseado\n",
    "product_id_deseado = '20001'  # Reemplaza esto con el código de producto que quieres filtrar\n",
    "\n",
    "# Asegurarse de que 'product_id' es del mismo tipo que los valores en df_ventas\n",
    "if df_ventas['product_id'].dtype == 'int64':\n",
    "    product_id_deseado = int(product_id_deseado)\n",
    "elif df_ventas['product_id'].dtype == 'float64':\n",
    "    product_id_deseado = float(product_id_deseado)\n",
    "\n",
    "df_filtrado = df_ventas[df_ventas['product_id'] == product_id_deseado]\n",
    "\n",
    "# Verificar que el filtrado no sea vacío\n",
    "if df_filtrado.empty:\n",
    "    print(f\"No hay datos para el product_id {product_id_deseado}\")\n",
    "else:\n",
    "    # Asegurarse de que la columna 'periodo' esté en formato datetime\n",
    "    df_filtrado['periodo'] = pd.to_datetime(df_filtrado['periodo'])\n",
    "\n",
    "    # Agrupar las ventas por período (puedes agrupar por mes, año, etc. según tu necesidad)\n",
    "    df_agrupado = df_filtrado.groupby(df_filtrado['periodo'].dt.to_period('M')).sum('tn').reset_index()\n",
    "    df_agrupado['periodo'] = df_agrupado['periodo'].dt.to_timestamp()\n",
    "\n",
    "    # Verificar que el agrupamiento no sea vacío\n",
    "    if df_agrupado.empty:\n",
    "        print(\"No hay datos después del agrupamiento\")\n",
    "    else:\n",
    "        # Graficar la evolución de las ventas\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df_agrupado['periodo'], df_agrupado['tn'], marker='o')\n",
    "        plt.title(f'Evolución de las ventas en toneladas para el producto {product_id_deseado}')\n",
    "        plt.xlabel('Período')\n",
    "        plt.ylabel('Ventas en toneladas (tn)')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e41f6ca-1be8-4f23-9bdb-42df7858846f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Product_id con mayores ventas:\n",
      "   product_id           tn\n",
      "0       20001  50340.39558\n",
      "1       20002  36337.25439\n",
      "2       20003  32004.15274\n",
      "3       20004  24178.15379\n",
      "4       20005  23191.21852\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n"
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "data:image/png;base64,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\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "image"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Agrupar por product_id y sumar las ventas (tn)\n",
    "df_suma_ventas = df_ventas.groupby('product_id')['tn'].sum().reset_index()\n",
    "\n",
    "# Ordenar por ventas en orden descendente\n",
    "df_suma_ventas = df_suma_ventas.sort_values(by='tn', ascending=False)\n",
    "\n",
    "# Mostrar los product_id con mayores ventas\n",
    "print(\"\\nProduct_id con mayores ventas:\")\n",
    "print(df_suma_ventas.head())\n",
    "\n",
    "# Graficar los 10 product_id con mayores ventas\n",
    "top_n = 10  # Número de productos a mostrar\n",
    "df_top_ventas = df_suma_ventas.head(top_n)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(df_top_ventas['product_id'].astype(str), df_top_ventas['tn'])\n",
    "plt.title('Top 10 Product_id con mayores ventas en toneladas')\n",
    "plt.xlabel('Product_id')\n",
    "plt.ylabel('Ventas en toneladas (tn)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fd62840-94d2-4673-b901-921e390338a8",
     "showTitle": false,
     "title": ""
    },
    "id": "AMCiAaIWNdmf"
   },
   "source": [
    "# Armado del dataset para los productos a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50329099-770b-4888-814a-d8fd854039b7",
     "showTitle": false,
     "title": ""
    },
    "id": "8f627665-bb59-455a-859b-c04b65a68a09"
   },
   "outputs": [],
   "source": [
    "# Armado de la lista de productos validos a predecir para el periodo\n",
    "product_ids_validos = df_predict['product_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0139d8d-dc40-434b-8c9d-61cc6af0fa57",
     "showTitle": false,
     "title": ""
    },
    "id": "9da04535-3490-49f0-b28b-dbdc8ef06f96"
   },
   "outputs": [],
   "source": [
    "# Filtrar el DataFrame original para quedarse solo con los product_id válidos\n",
    "# En un nuevo Data Frame llamado \"DATA\"\n",
    "data = df_ventas[df_ventas['product_id'].isin(product_ids_validos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ec6b368-24a0-40cd-b594-ec3c21eb0dc2",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "collapsed": true,
    "id": "a3f1d96b-1c62-4d32-8ea0-81880e95abeb",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "7c92f3c5-c5ae-462a-c0c3-e9d4a141116d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10234</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.05300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10032</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>0.13628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10217</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>0.03028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10125</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>0.02271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>10012</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>1.54452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>periodo</th>\n      <th>customer_id</th>\n      <th>product_id</th>\n      <th>plan_precios_cuidados</th>\n      <th>cust_request_qty</th>\n      <th>cust_request_tn</th>\n      <th>tn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2017-01-01</td>\n      <td>10234</td>\n      <td>20524</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.05300</td>\n      <td>0.05300</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2017-01-01</td>\n      <td>10032</td>\n      <td>20524</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.13628</td>\n      <td>0.13628</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2017-01-01</td>\n      <td>10217</td>\n      <td>20524</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.03028</td>\n      <td>0.03028</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2017-01-01</td>\n      <td>10125</td>\n      <td>20524</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.02271</td>\n      <td>0.02271</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2017-01-01</td>\n      <td>10012</td>\n      <td>20524</td>\n      <td>0</td>\n      <td>11</td>\n      <td>1.54452</td>\n      <td>1.54452</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3935d1ff-3804-4870-b8ca-4facd338a1d2",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "7c4574e0-b363-4382-86d8-8d80e74f865e",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "cf336074-103f-4f8b-af12-e497acb8b1f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2293481 entries, 0 to 2945817\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   periodo                datetime64[ns]\n",
      " 1   customer_id            int64         \n",
      " 2   product_id             int64         \n",
      " 3   plan_precios_cuidados  int64         \n",
      " 4   cust_request_qty       int64         \n",
      " 5   cust_request_tn        float64       \n",
      " 6   tn                     float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(4)\n",
      "memory usage: 140.0 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a0a64d5-6524-4a73-b848-7aa0cabf9541",
     "showTitle": false,
     "title": ""
    },
    "id": "ed031c9e-1642-4296-90bc-fad03b98512e"
   },
   "outputs": [],
   "source": [
    "# Función para agregar los valores de 'tn' por 'product_id' y 'periodo'\n",
    "\n",
    "# Definir la función aggregate_data\n",
    "def aggregate_data(df_ventas):\n",
    "    return df_ventas.groupby(['product_id', 'periodo','cust_request_qty','customer_id'])['tn'].sum().reset_index()\n",
    "\n",
    "# Agrupar los datos\n",
    "data = aggregate_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d25eb008-d586-4bf2-a609-d7794170d936",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "collapsed": true,
    "id": "5b16f3e4-098a-44ec-9e3c-0f3ab5426b5d",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e2b8f04e-cbf9-4a46-8c8b-d07b8b322ba6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>periodo</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>10014</td>\n",
       "      <td>0.12312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>10018</td>\n",
       "      <td>1.67895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>10024</td>\n",
       "      <td>0.61562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>10042</td>\n",
       "      <td>0.36937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>10043</td>\n",
       "      <td>0.12312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>product_id</th>\n      <th>periodo</th>\n      <th>cust_request_qty</th>\n      <th>customer_id</th>\n      <th>tn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20001</td>\n      <td>2017-01-01</td>\n      <td>1</td>\n      <td>10014</td>\n      <td>0.12312</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20001</td>\n      <td>2017-01-01</td>\n      <td>1</td>\n      <td>10018</td>\n      <td>1.67895</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20001</td>\n      <td>2017-01-01</td>\n      <td>1</td>\n      <td>10024</td>\n      <td>0.61562</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20001</td>\n      <td>2017-01-01</td>\n      <td>1</td>\n      <td>10042</td>\n      <td>0.36937</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20001</td>\n      <td>2017-01-01</td>\n      <td>1</td>\n      <td>10043</td>\n      <td>0.12312</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43f3b64f-ff2f-48b8-8cc9-390461672e4e",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "e0b183b4-2a66-44e6-9e1d-ca493f0da1f7",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e7d7aeb8-8a4d-4085-853f-aaf5660f85bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         product_id    periodo  ...  cust_request_tn        tn\n",
      "0             20001 2017-01-01  ...         99.43861  99.43861\n",
      "1             20001 2017-01-01  ...          0.12312   0.12312\n",
      "2             20001 2017-01-01  ...          0.24625   0.24625\n",
      "3             20001 2017-01-01  ...          1.23123   1.23123\n",
      "4             20001 2017-01-01  ...          0.06716   0.06716\n",
      "...             ...        ...  ...              ...       ...\n",
      "2299207       21276 2019-11-01  ...          0.00148   0.00148\n",
      "2299208       21276 2019-12-01  ...          0.00075   0.00075\n",
      "2299209       21276 2019-12-01  ...          0.00594   0.00594\n",
      "2299210       21276 2019-12-01  ...          0.00075   0.00075\n",
      "2299211       21276 2019-12-01  ...          0.00148   0.00148\n",
      "\n",
      "[2299212 rows x 7 columns]\n",
      "\n",
      "DataFrame con todos los product_id en todos los periodos:\n",
      "         product_id    periodo  ...  cust_request_tn  tn\n",
      "0             20001 2017-01-01  ...         99.43861  99\n",
      "1             20001 2017-01-01  ...          0.12312   0\n",
      "2             20001 2017-01-01  ...          0.24625   0\n",
      "3             20001 2017-01-01  ...          1.23123   1\n",
      "4             20001 2017-01-01  ...          0.06716   0\n",
      "...             ...        ...  ...              ...  ..\n",
      "2299207       21276 2019-11-01  ...          0.00148   0\n",
      "2299208       21276 2019-12-01  ...          0.00075   0\n",
      "2299209       21276 2019-12-01  ...          0.00594   0\n",
      "2299210       21276 2019-12-01  ...          0.00075   0\n",
      "2299211       21276 2019-12-01  ...          0.00148   0\n",
      "\n",
      "[2299212 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Obtener todos los productos y periodos únicos\n",
    "all_product_ids = data['product_id'].unique()\n",
    "all_periods = data['periodo'].unique()\n",
    "\n",
    "# Crear un DataFrame con todas las combinaciones posibles de product_id y periodo\n",
    "all_combinations = pd.MultiIndex.from_product([all_product_ids, all_periods], names=['product_id', 'periodo']).to_frame(index=False)\n",
    "\n",
    "# Realizar el merge con el DataFrame original, llenando los valores faltantes con 0\n",
    "df_complete = pd.merge(all_combinations, df_ventas, on=['product_id', 'periodo'], how='left').fillna(0)\n",
    "\n",
    "# Verificar el resultado\n",
    "print(df_complete)\n",
    "\n",
    "# Asegurarse de que los tipos de datos sean correctos\n",
    "df_complete['cust_request_qty'] = df_complete['cust_request_qty'].astype(int)\n",
    "df_complete['tn'] = df_complete['tn'].astype(int)\n",
    "\n",
    "# Mostrar el DataFrame completo\n",
    "print(\"\\nDataFrame con todos los product_id en todos los periodos:\")\n",
    "print(df_complete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e3fc978-195e-4428-9380-29e1c808f76e",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "644767d7-32e8-438f-8521-af35d2027aa0",
    "outputId": "4f64cc30-c932-4489-8428-c250b050541e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de valores únicos en 'product_id': 780\n",
      "product_id                        int64\n",
      "periodo                  datetime64[ns]\n",
      "customer_id                     float64\n",
      "plan_precios_cuidados           float64\n",
      "cust_request_qty                  int64\n",
      "cust_request_tn                 float64\n",
      "tn                                int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Contar la cantidad de valores únicos en la columna 'product_id'\n",
    "unique_product_ids = df_complete['product_id'].nunique()\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(\"Cantidad de valores únicos en 'product_id':\", unique_product_ids)\n",
    "print(df_complete.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdfe9b05-77e3-427a-85a3-a8e0b8eab6d2",
     "showTitle": false,
     "title": ""
    },
    "id": "b2008d08-5462-4770-8518-917f2dba52e7"
   },
   "outputs": [],
   "source": [
    "# Función para agregar los valores de 'tn' por 'product_id' y 'periodo'\n",
    "\n",
    "# Definir la función aggregate_data\n",
    "def aggregate_data(df_complete):\n",
    "    return df_complete.groupby(['product_id', 'periodo','cust_request_qty','customer_id'])['tn'].sum().reset_index()\n",
    "\n",
    "# Agrupar los datos\n",
    "data2 = aggregate_data(df_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5326ccb9-2af8-49bf-b6ea-9c26bbdf3c74",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "9a5f05d0-8161-403c-9d76-9372006f2e9a",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "19f1c9b5-0e94-4436-d82a-4d3a4d026550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         product_id    periodo  cust_request_qty  customer_id  tn\n",
      "0             20001 2017-01-01                 1      10014.0   0\n",
      "1             20001 2017-01-01                 1      10018.0   1\n",
      "2             20001 2017-01-01                 1      10024.0   0\n",
      "3             20001 2017-01-01                 1      10042.0   0\n",
      "4             20001 2017-01-01                 1      10043.0   0\n",
      "...             ...        ...               ...          ...  ..\n",
      "2299207       21276 2019-11-01                 2      10550.0   0\n",
      "2299208       21276 2019-12-01                 1      10029.0   0\n",
      "2299209       21276 2019-12-01                 1      10052.0   0\n",
      "2299210       21276 2019-12-01                 1      10219.0   0\n",
      "2299211       21276 2019-12-01                 1      10289.0   0\n",
      "\n",
      "[2299212 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9294ec99-1e7b-4c42-aa1a-841ad7d18e95",
     "showTitle": false,
     "title": ""
    },
    "id": "_Pc3ruQcnWt7"
   },
   "source": [
    "# Calulamos **LAGs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebb7ebd0-1978-4870-b08d-2c2854bcb91c",
     "showTitle": false,
     "title": ""
    },
    "id": "EeRAxL-7b6Cg"
   },
   "outputs": [],
   "source": [
    "# Agregar lags para la característica 'tn' (variable objetivo)\n",
    "lags = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]  \n",
    "\n",
    "# Agregar lags para 'tn' en el conjunto de datos de data\n",
    "for lag in lags:\n",
    "    data2[f'tn_lag_{lag}'] = data2.groupby('product_id')['tn'].shift(lag)\n",
    "# Reemplazar NaN por 0 en las columnas de lags\n",
    "lag_columns = [f'tn_lag_{lag}' for lag in lags]\n",
    "data2[lag_columns] = data2[lag_columns].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "618c41f9-bee3-46e2-9578-7b6652b331ce",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "tvwN5XCLcSRS",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "7005a0bd-169c-4c3b-932b-623d900752ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         product_id    periodo  cust_request_qty  customer_id  tn  tn_lag_1  \\\n",
      "0             20001 2017-01-01                 1      10014.0   0       0.0   \n",
      "1             20001 2017-01-01                 1      10018.0   1       0.0   \n",
      "2             20001 2017-01-01                 1      10024.0   0       1.0   \n",
      "3             20001 2017-01-01                 1      10042.0   0       0.0   \n",
      "4             20001 2017-01-01                 1      10043.0   0       0.0   \n",
      "...             ...        ...               ...          ...  ..       ...   \n",
      "2299207       21276 2019-11-01                 2      10550.0   0       0.0   \n",
      "2299208       21276 2019-12-01                 1      10029.0   0       0.0   \n",
      "2299209       21276 2019-12-01                 1      10052.0   0       0.0   \n",
      "2299210       21276 2019-12-01                 1      10219.0   0       0.0   \n",
      "2299211       21276 2019-12-01                 1      10289.0   0       0.0   \n",
      "\n",
      "         tn_lag_2  tn_lag_3  tn_lag_6  tn_lag_7  ...  tn_lag_15  tn_lag_16  \\\n",
      "0             0.0       0.0       0.0       0.0  ...        0.0        0.0   \n",
      "1             0.0       0.0       0.0       0.0  ...        0.0        0.0   \n",
      "2             0.0       0.0       0.0       0.0  ...        0.0        0.0   \n",
      "3             1.0       0.0       0.0       0.0  ...        0.0        0.0   \n",
      "4             0.0       1.0       0.0       0.0  ...        0.0        0.0   \n",
      "...           ...       ...       ...       ...  ...        ...        ...   \n",
      "2299207       0.0       0.0       0.0       0.0  ...        0.0        0.0   \n",
      "2299208       0.0       0.0       0.0       0.0  ...        0.0        0.0   \n",
      "2299209       0.0       0.0       0.0       0.0  ...        0.0        0.0   \n",
      "2299210       0.0       0.0       0.0       0.0  ...        0.0        0.0   \n",
      "2299211       0.0       0.0       0.0       0.0  ...        0.0        0.0   \n",
      "\n",
      "         tn_lag_17  tn_lag_18  tn_lag_19  tn_lag_20  tn_lag_21  tn_lag_22  \\\n",
      "0              0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "1              0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "2              0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "3              0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "4              0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "...            ...        ...        ...        ...        ...        ...   \n",
      "2299207        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "2299208        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "2299209        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "2299210        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "2299211        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "\n",
      "         tn_lag_23  tn_lag_24  \n",
      "0              0.0        0.0  \n",
      "1              0.0        0.0  \n",
      "2              0.0        0.0  \n",
      "3              0.0        0.0  \n",
      "4              0.0        0.0  \n",
      "...            ...        ...  \n",
      "2299207        0.0        0.0  \n",
      "2299208        0.0        0.0  \n",
      "2299209        0.0        0.0  \n",
      "2299210        0.0        0.0  \n",
      "2299211        0.0        0.0  \n",
      "\n",
      "[2299212 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5b5c259-2dd7-479c-b19d-a5a7f6e21064",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "5OTzOEbkc-5T",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "7e716526-8a80-479d-d4b1-93cf15246814"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         product_id    periodo  cust_request_qty  customer_id  tn  tn_lag_1  \\\n",
      "0             20001 2017-01-01                 1      10014.0   0       0.0   \n",
      "1             20001 2017-01-01                 1      10018.0   1       0.0   \n",
      "2             20001 2017-01-01                 1      10024.0   0       1.0   \n",
      "3             20001 2017-01-01                 1      10042.0   0       0.0   \n",
      "4             20001 2017-01-01                 1      10043.0   0       0.0   \n",
      "...             ...        ...               ...          ...  ..       ...   \n",
      "2299207       21276 2019-11-01                 2      10550.0   0       0.0   \n",
      "2299208       21276 2019-12-01                 1      10029.0   0       0.0   \n",
      "2299209       21276 2019-12-01                 1      10052.0   0       0.0   \n",
      "2299210       21276 2019-12-01                 1      10219.0   0       0.0   \n",
      "2299211       21276 2019-12-01                 1      10289.0   0       0.0   \n",
      "\n",
      "         tn_lag_2  tn_lag_3  tn_lag_6  tn_lag_7  ...  tn_lag_15  tn_lag_16  \\\n",
      "0             0.0       0.0       0.0       0.0  ...        0.0        0.0   \n",
      "1             0.0       0.0       0.0       0.0  ...        0.0        0.0   \n",
      "2             0.0       0.0       0.0       0.0  ...        0.0        0.0   \n",
      "3             1.0       0.0       0.0       0.0  ...        0.0        0.0   \n",
      "4             0.0       1.0       0.0       0.0  ...        0.0        0.0   \n",
      "...           ...       ...       ...       ...  ...        ...        ...   \n",
      "2299207       0.0       0.0       0.0       0.0  ...        0.0        0.0   \n",
      "2299208       0.0       0.0       0.0       0.0  ...        0.0        0.0   \n",
      "2299209       0.0       0.0       0.0       0.0  ...        0.0        0.0   \n",
      "2299210       0.0       0.0       0.0       0.0  ...        0.0        0.0   \n",
      "2299211       0.0       0.0       0.0       0.0  ...        0.0        0.0   \n",
      "\n",
      "         tn_lag_17  tn_lag_18  tn_lag_19  tn_lag_20  tn_lag_21  tn_lag_22  \\\n",
      "0              0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "1              0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "2              0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "3              0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "4              0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "...            ...        ...        ...        ...        ...        ...   \n",
      "2299207        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "2299208        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "2299209        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "2299210        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "2299211        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "\n",
      "         tn_lag_23  tn_lag_24  \n",
      "0              0.0        0.0  \n",
      "1              0.0        0.0  \n",
      "2              0.0        0.0  \n",
      "3              0.0        0.0  \n",
      "4              0.0        0.0  \n",
      "...            ...        ...  \n",
      "2299207        0.0        0.0  \n",
      "2299208        0.0        0.0  \n",
      "2299209        0.0        0.0  \n",
      "2299210        0.0        0.0  \n",
      "2299211        0.0        0.0  \n",
      "\n",
      "[2299212 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "data=data2\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "251ba342-714e-426e-ab4c-9b7324845388",
     "showTitle": false,
     "title": ""
    },
    "id": "yaoITjk0nIA5"
   },
   "source": [
    "# LightGBM **Primer Version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d541ef6-c889-43d1-88c8-ee2525d78d69",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4I5iPMJqiCF9",
    "outputId": "c6ff43cd-226d-44e2-da57-40c65091c597"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 589\n",
      "[LightGBM] [Info] Number of data points in the train set: 1839369, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 0.352071\n",
      "Predicciones guardadas en 'predicciones_feb_2020.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#data = data2\n",
    "\n",
    "# Crear características adicionales (features)\n",
    "data['year'] = data['periodo'].dt.year\n",
    "data['month'] = data['periodo'].dt.month\n",
    "\n",
    "# Filtrar los datos hasta 2019-12-01 para entrenamiento\n",
    "train_data = data[data['periodo'] <= '2019-12-01']\n",
    "\n",
    "# Definir las características y el target\n",
    "features = ['product_id', 'customer_id', 'year', 'month', 'cust_request_qty']\n",
    "target = 'tn'\n",
    "\n",
    "X = train_data[features]\n",
    "y = train_data[target]\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo LightGBM\n",
    "model = LGBMRegressor()\n",
    "model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
    "\n",
    "# Crear el DataFrame para las predicciones de febrero de 2020\n",
    "# Usamos todas las combinaciones únicas de product_id y customer_id en el dataset\n",
    "unique_product_ids = data['product_id'].unique()\n",
    "unique_customer_ids = data['customer_id'].unique()\n",
    "prediction_data = pd.DataFrame([(pid, cid) for pid in unique_product_ids for cid in unique_customer_ids], columns=['product_id', 'customer_id'])\n",
    "\n",
    "# Añadir las columnas necesarias\n",
    "prediction_data['year'] = 2020\n",
    "prediction_data['month'] = 2\n",
    "\n",
    "# Para 'cust_request_qty', usamos el promedio de solicitudes por combinación de product_id y customer_id\n",
    "cust_request_qty_means = data.groupby(['product_id', 'customer_id'])['cust_request_qty'].mean().reset_index()\n",
    "prediction_data = prediction_data.merge(cust_request_qty_means, on=['product_id', 'customer_id'], how='left')\n",
    "\n",
    "# Rellenar NaNs en 'cust_request_qty' con 0 si no hay datos históricos para esa combinación\n",
    "prediction_data['cust_request_qty'] = prediction_data['cust_request_qty'].fillna(0)\n",
    "\n",
    "# Asignar valores de 'tn'\n",
    "prediction_data['tn'] = data['tn']\n",
    "\n",
    "# Agregar lags para 'tn' en el conjunto de datos de predicción\n",
    "lags = [1, 2, 3, 6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]\n",
    "for lag in lags:\n",
    "    prediction_data[f'tn_lag_{lag}'] = prediction_data.groupby('product_id')['tn'].shift(lag)\n",
    "\n",
    "# Hacer predicciones\n",
    "X_pred = prediction_data[features]\n",
    "prediction_data['tn'] = model.predict(X_pred)\n",
    "\n",
    "# Agrupar por product_id y sumar las predicciones de tn\n",
    "grouped_predictions = prediction_data.groupby('product_id')['tn'].sum().reset_index()\n",
    "\n",
    "# Añadir la columna de periodo\n",
    "grouped_predictions['periodo'] = '202002'\n",
    "\n",
    "# Seleccionar columnas y guardar en CSV\n",
    "output = grouped_predictions[['product_id', 'tn']]\n",
    "output.to_csv('predicciones_feb_2020.csv', index=False)\n",
    "\n",
    "print(\"Predicciones guardadas en 'predicciones_feb_2020.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c00ee721-1b21-4763-bb06-87503aa4d8f8",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "AWM-q9M5gs02",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "635d9a30-8200-4c55-a86d-b31c7e83e1da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         product_id    periodo  cust_request_qty  customer_id  tn  year  \\\n",
      "0             20001 2017-01-01                 1      10014.0   0  2017   \n",
      "1             20001 2017-01-01                 1      10018.0   1  2017   \n",
      "2             20001 2017-01-01                 1      10024.0   0  2017   \n",
      "3             20001 2017-01-01                 1      10042.0   0  2017   \n",
      "4             20001 2017-01-01                 1      10043.0   0  2017   \n",
      "...             ...        ...               ...          ...  ..   ...   \n",
      "2299207       21276 2019-11-01                 2      10550.0   0  2019   \n",
      "2299208       21276 2019-12-01                 1      10029.0   0  2019   \n",
      "2299209       21276 2019-12-01                 1      10052.0   0  2019   \n",
      "2299210       21276 2019-12-01                 1      10219.0   0  2019   \n",
      "2299211       21276 2019-12-01                 1      10289.0   0  2019   \n",
      "\n",
      "         month  tn_lag_1  tn_lag_2  tn_lag_3  tn_lag_6  tn_lag_12  \n",
      "0            1       0.0       0.0       0.0       0.0        0.0  \n",
      "1            1       0.0       0.0       0.0       0.0        0.0  \n",
      "2            1       1.0       0.0       0.0       0.0        0.0  \n",
      "3            1       0.0       1.0       0.0       0.0        0.0  \n",
      "4            1       0.0       0.0       1.0       0.0        0.0  \n",
      "...        ...       ...       ...       ...       ...        ...  \n",
      "2299207     11       0.0       0.0       0.0       0.0        0.0  \n",
      "2299208     12       0.0       0.0       0.0       0.0        0.0  \n",
      "2299209     12       0.0       0.0       0.0       0.0        0.0  \n",
      "2299210     12       0.0       0.0       0.0       0.0        0.0  \n",
      "2299211     12       0.0       0.0       0.0       0.0        0.0  \n",
      "\n",
      "[2299212 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38f56217-6e61-4378-a697-acc45a6bb774",
     "showTitle": false,
     "title": ""
    },
    "id": "yAxRWg9xnA9q"
   },
   "source": [
    "# LightGBM CON **LAGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87f48346-de73-4d78-b0c6-3ec8bb2604fb",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hI-vEmjUYOJQ",
    "outputId": "650dd68d-1639-41c8-b40c-7ff8ed6a299a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.130672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1005\n",
      "[LightGBM] [Info] Number of data points in the train set: 1839369, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352071\n",
      "Predicciones guardadas en 'predicciones_feb_2020.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = data2\n",
    "\n",
    "# Crear características adicionales (features)\n",
    "data['year'] = data['periodo'].dt.year\n",
    "data['month'] = data['periodo'].dt.month\n",
    "\n",
    "# Agregar lags para 'tn' en el conjunto de datos\n",
    "lags = [1, 2, 3, 6, 12]\n",
    "for lag in lags:\n",
    "    data[f'tn_lag_{lag}'] = data.groupby('product_id')['tn'].shift(lag)\n",
    "\n",
    "# Filtrar los datos hasta 2019-12-01 para entrenamiento\n",
    "train_data = data[data['periodo'] <= '2019-12-01']\n",
    "\n",
    "# Definir las características y el target\n",
    "features = ['product_id', 'customer_id', 'year', 'month', 'cust_request_qty'] + [f'tn_lag_{lag}' for lag in lags]\n",
    "target = 'tn'\n",
    "\n",
    "X = train_data[features]\n",
    "y = train_data[target]\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo LightGBM\n",
    "model = LGBMRegressor()\n",
    "model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
    "\n",
    "# Crear el DataFrame para las predicciones de febrero de 2020\n",
    "# Usamos todas las combinaciones únicas de product_id y customer_id en el dataset original\n",
    "unique_product_ids = data2['product_id'].unique()\n",
    "unique_customer_ids = data2['customer_id'].unique()\n",
    "prediction_data = pd.DataFrame([(pid, cid) for pid in unique_product_ids for cid in unique_customer_ids], columns=['product_id', 'customer_id'])\n",
    "# Añadir las columnas necesarias para las características adicionales\n",
    "prediction_data['year'] = 2020\n",
    "prediction_data['month'] = 2\n",
    "# Agregar la columna 'tn' al DataFrame de predicciones\n",
    "prediction_data['tn'] = np.nan  # Creamos la columna con NaN\n",
    "\n",
    "# Agregar lags para 'tn' en el conjunto de datos de predicción\n",
    "for lag in lags:\n",
    "    prediction_data[f'tn_lag_{lag}'] = prediction_data.groupby('product_id')['tn'].shift(lag)\n",
    "\n",
    "# Para 'cust_request_qty', usamos el promedio de solicitudes por combinación de product_id y customer_id\n",
    "cust_request_qty_means = data.groupby(['product_id', 'customer_id'])['cust_request_qty'].mean().reset_index()\n",
    "prediction_data = prediction_data.merge(cust_request_qty_means, on=['product_id', 'customer_id'], how='left')\n",
    "\n",
    "# Rellenar NaNs en 'cust_request_qty' con 0 si no hay datos históricos para esa combinación\n",
    "prediction_data['cust_request_qty'] = prediction_data['cust_request_qty'].fillna(0)\n",
    "\n",
    "# Hacer predicciones\n",
    "X_pred = prediction_data[features]\n",
    "prediction_data['tn'] = model.predict(X_pred)\n",
    "\n",
    "# Agrupar por product_id y sumar las predicciones de tn\n",
    "grouped_predictions = prediction_data.groupby('product_id')['tn'].sum().reset_index()\n",
    "\n",
    "# Añadir la columna de periodo\n",
    "grouped_predictions['periodo'] = '202002'\n",
    "\n",
    "# Seleccionar columnas y guardar en CSV\n",
    "output = grouped_predictions[['product_id', 'tn']]\n",
    "output.to_csv('predicciones_feb_2020.csv', index=False)\n",
    "\n",
    "print(\"Predicciones guardadas en 'predicciones_feb_2020.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fccb30ad-efcb-4dbe-8e3b-31dec0435fcf",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VP6wCe6l7gD",
    "outputId": "f2eb5ed7-125c-4381-d97b-f4882499285c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-78-8cd773806014>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X.fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones guardadas en 'predicciones_feb_2020.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = data2\n",
    "\n",
    "# Crear características adicionales (features)\n",
    "data['year'] = data['periodo'].dt.year\n",
    "data['month'] = data['periodo'].dt.month\n",
    "\n",
    "# Agregar lags para 'tn' en el conjunto de datos\n",
    "lags = [1, 2, 3, 6, 12]\n",
    "for lag in lags:\n",
    "    data[f'tn_lag_{lag}'] = data.groupby('product_id')['tn'].shift(lag)\n",
    "\n",
    "# Filtrar los datos hasta 2019-12-01 para entrenamiento\n",
    "train_data = data[data['periodo'] <= '2019-12-01']\n",
    "\n",
    "# Definir las características y el target\n",
    "features = ['product_id', 'customer_id', 'year', 'month', 'cust_request_qty'] + [f'tn_lag_{lag}' for lag in lags]\n",
    "target = 'tn'\n",
    "\n",
    "X = train_data[features]\n",
    "y = train_data[target]\n",
    "\n",
    "# Reemplazar valores faltantes con 0\n",
    "X.fillna(0, inplace=True)\n",
    "y.fillna(0, inplace=True)\n",
    "\n",
    "# Entrenar un modelo de regresión lineal para cada product_id\n",
    "product_ids = data['product_id'].unique()\n",
    "regressions = {}\n",
    "for pid in product_ids:\n",
    "    X_pid = X[X['product_id'] == pid]\n",
    "    y_pid = y[X['product_id'] == pid]\n",
    "    regression = LinearRegression()\n",
    "    regression.fit(X_pid, y_pid)\n",
    "    regressions[pid] = regression\n",
    "\n",
    "# Crear el DataFrame para las predicciones de febrero de 2020\n",
    "# Usamos todas las combinaciones únicas de product_id y customer_id en el dataset original\n",
    "unique_product_ids = data2['product_id'].unique()\n",
    "unique_customer_ids = data2['customer_id'].unique()\n",
    "prediction_data = pd.DataFrame([(pid, cid) for pid in unique_product_ids for cid in unique_customer_ids], columns=['product_id', 'customer_id'])\n",
    "# Añadir las columnas necesarias para las características adicionales\n",
    "prediction_data['year'] = 2020\n",
    "prediction_data['month'] = 2\n",
    "# Agregar la columna 'tn' al DataFrame de predicciones\n",
    "prediction_data['tn'] = np.nan  # Creamos la columna con NaN\n",
    "\n",
    "# Agregar lags para 'tn' en el conjunto de datos de predicción\n",
    "for lag in lags:\n",
    "    prediction_data[f'tn_lag_{lag}'] = prediction_data.groupby('product_id')['tn'].shift(lag)\n",
    "\n",
    "# Para 'cust_request_qty', usamos el promedio de solicitudes por combinación de product_id y customer_id\n",
    "cust_request_qty_means = data.groupby(['product_id', 'customer_id'])['cust_request_qty'].mean().reset_index()\n",
    "prediction_data = prediction_data.merge(cust_request_qty_means, on=['product_id', 'customer_id'], how='left')\n",
    "\n",
    "# Rellenar NaNs en 'cust_request_qty' con 0 si no hay datos históricos para esa combinación\n",
    "prediction_data['cust_request_qty'] = prediction_data['cust_request_qty'].fillna(0)\n",
    "\n",
    "# Reemplazar valores faltantes con 0\n",
    "prediction_data.fillna(0, inplace=True)\n",
    "\n",
    "# Predicciones usando regresión lineal para cada product_id\n",
    "for pid, regression in regressions.items():\n",
    "    X_pid_pred = prediction_data[prediction_data['product_id'] == pid][features]\n",
    "    prediction_data.loc[prediction_data['product_id'] == pid, 'tn'] = regression.predict(X_pid_pred)\n",
    "\n",
    "# Hacer predicciones finales usando LightGBM\n",
    "X_pred = prediction_data[features]\n",
    "prediction_data['tn'] = model.predict(X_pred)\n",
    "\n",
    "# Operación inversa para obtener los resultados correctos\n",
    "for pid, regression in regressions.items():\n",
    "    X_pid_pred = prediction_data[prediction_data['product_id'] == pid][features]\n",
    "    prediction_data.loc[prediction_data['product_id'] == pid, 'tn'] -= regression.predict(X_pid_pred)\n",
    "\n",
    "# Agrupar por product_id y sumar las predicciones de tn\n",
    "grouped_predictions = prediction_data.groupby('product_id')['tn'].sum().reset_index()\n",
    "\n",
    "# Añadir la columna de periodo\n",
    "grouped_predictions['periodo'] = '202002'\n",
    "\n",
    "# Seleccionar columnas y guardar en CSV\n",
    "output = grouped_predictions[['product_id', 'tn']]\n",
    "output.to_csv('predicciones_feb_2020.csv', index=False)\n",
    "\n",
    "print(\"Predicciones guardadas en 'predicciones_feb_2020.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56c6736d-0ce2-4a12-b3ba-cd3affdd2a6e",
     "showTitle": false,
     "title": ""
    },
    "id": "4AiSoIN7M0mj"
   },
   "source": [
    "# LightGBM con **Regresion lineal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd7d648a-a569-489c-a855-b2165f58e61e",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rKVkwBYJY0D",
    "outputId": "ace704fb-826e-460c-c3d5-7916d7749f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.211673 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1000\n",
      "[LightGBM] [Info] Number of data points in the train set: 1839369, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352071\n",
      "Predicciones guardadas en 'predicciones_feb_2020.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = data2.copy()\n",
    "\n",
    "# Crear características adicionales (features)\n",
    "data['year'] = data['periodo'].dt.year\n",
    "data['month'] = data['periodo'].dt.month\n",
    "\n",
    "# Agregar lags para 'tn' en el conjunto de datos\n",
    "lags = [1, 2, 3, 6, 12]\n",
    "for lag in lags:\n",
    "    data[f'tn_lag_{lag}'] = data.groupby('product_id')['tn'].shift(lag)\n",
    "\n",
    "# Reemplazar valores faltantes con 0\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Filtrar los datos hasta 2019-12-01 para entrenamiento\n",
    "train_data = data[data['periodo'] <= '2019-12-01']\n",
    "\n",
    "# Definir las características y el target\n",
    "features = ['product_id', 'customer_id', 'year', 'month', 'cust_request_qty'] + [f'tn_lag_{lag}' for lag in lags]\n",
    "target = 'tn'\n",
    "\n",
    "X = train_data[features]\n",
    "y = train_data[target]\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar un modelo de regresión lineal para cada product_id\n",
    "product_ids = data['product_id'].unique()\n",
    "regressions = {}\n",
    "coefs = {}\n",
    "for pid in product_ids:\n",
    "    X_pid = X[X['product_id'] == pid]\n",
    "    y_pid = y[X['product_id'] == pid]\n",
    "    regression = LinearRegression()\n",
    "    regression.fit(X_pid, y_pid)\n",
    "    regressions[pid] = regression\n",
    "    coefs[pid] = (regression.coef_[0], regression.intercept_)\n",
    "\n",
    "# Crear el DataFrame para las predicciones de febrero de 2020\n",
    "unique_product_ids = data2['product_id'].unique()\n",
    "unique_customer_ids = data2['customer_id'].unique()\n",
    "prediction_data = pd.DataFrame([(pid, cid) for pid in unique_product_ids for cid in unique_customer_ids], columns=['product_id', 'customer_id'])\n",
    "\n",
    "# Añadir las columnas necesarias para las características adicionales\n",
    "prediction_data['year'] = 2020\n",
    "prediction_data['month'] = 2\n",
    "\n",
    "# Para 'cust_request_qty', usamos el promedio de solicitudes por combinación de product_id y customer_id\n",
    "cust_request_qty_means = data.groupby(['product_id', 'customer_id'])['cust_request_qty'].mean().reset_index()\n",
    "prediction_data = prediction_data.merge(cust_request_qty_means, on=['product_id', 'customer_id'], how='left')\n",
    "\n",
    "# Reemplazar valores faltantes con 0\n",
    "prediction_data.fillna(0, inplace=True)\n",
    "\n",
    "# Agregar lags para 'tn' en el conjunto de datos de predicción\n",
    "for lag in lags:\n",
    "    lag_col = f'tn_lag_{lag}'\n",
    "    prediction_data[lag_col] = 0\n",
    "    for pid in unique_product_ids:\n",
    "        mask = prediction_data['product_id'] == pid\n",
    "        if lag_col in data.columns:\n",
    "            data_lags = data.loc[data['product_id'] == pid, lag_col].values\n",
    "            pred_lags = prediction_data.loc[mask, lag_col]\n",
    "            prediction_data.loc[mask, lag_col] = data_lags[-len(pred_lags):] if len(data_lags) >= len(pred_lags) else np.pad(data_lags, (len(pred_lags) - len(data_lags), 0), 'constant')\n",
    "\n",
    "# Predicciones usando regresión lineal para cada product_id\n",
    "for pid, regression in regressions.items():\n",
    "    X_pid_pred = prediction_data[prediction_data['product_id'] == pid][features]\n",
    "    prediction_data.loc[prediction_data['product_id'] == pid, 'tn'] = regression.predict(X_pid_pred)\n",
    "\n",
    "# Hacer predicciones finales usando LightGBM\n",
    "model = LGBMRegressor()\n",
    "model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
    "X_pred = prediction_data[features]\n",
    "prediction_data['transformed_tn'] = model.predict(X_pred)\n",
    "\n",
    "# Invertir la transformación para obtener los valores originales\n",
    "for pid, (coef, intercept) in coefs.items():\n",
    "    mask = prediction_data['product_id'] == pid\n",
    "    prediction_data.loc[mask, 'tn'] = prediction_data.loc[mask, 'transformed_tn'] * coef + intercept\n",
    "\n",
    "# Agrupar por product_id y sumar las predicciones de tn\n",
    "grouped_predictions = prediction_data.groupby('product_id')['tn'].sum().reset_index()\n",
    "\n",
    "# Añadir la columna de periodo\n",
    "grouped_predictions['periodo'] = '202002'\n",
    "\n",
    "# Seleccionar columnas y guardar en CSV\n",
    "output = grouped_predictions[['product_id', 'tn']]\n",
    "output.to_csv('predicciones_feb_2020.csv', index=False)\n",
    "\n",
    "print(\"Predicciones guardadas en 'predicciones_feb_2020.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "376101f9-1438-413d-b54d-3ff3c79b6647",
     "showTitle": false,
     "title": ""
    },
    "id": "7ZqACfCnQI-j"
   },
   "source": [
    "# LigthGBM normalizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "115c1c1c-f262-43db-8386-fb5de59550df",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9qZCbheQHeY",
    "outputId": "796d9d25-ab15-4eb0-a002-9cbc4040eb3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.122955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096011 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.128198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.142960 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.133335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.127476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.126492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.153670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.105211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.130013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.128426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.140007 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.136865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092045 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.128108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085830 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.216773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.124643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.228124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083857 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.127983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.218013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.160785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.112841 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.110416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091782 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.093812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.194647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.157583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.162382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.145038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084886 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.128766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.226138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.127098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.149595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.208382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095818 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.131470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.140853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084690 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.241684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125835 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.217880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.124352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.131264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123750 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082143 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.139606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.141913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.111556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.145243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.130716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.159322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.136630 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.143740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352096\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.085223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1023\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.350355\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1014\n",
      "[LightGBM] [Info] Number of data points in the train set: 1226246, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.353763\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=100\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1006\n",
      "[LightGBM] [Info] Number of data points in the train set: 1839369, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 0.352071\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "Predicciones guardadas en 'predicciones_feb_2020.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = data2.copy()\n",
    "\n",
    "# Crear características adicionales (features)\n",
    "data['year'] = data['periodo'].dt.year\n",
    "data['month'] = data['periodo'].dt.month\n",
    "\n",
    "# Agregar lags para 'tn' en el conjunto de datos\n",
    "lags = [1, 2, 3, 6, 12]\n",
    "for lag in lags:\n",
    "    data[f'tn_lag_{lag}'] = data.groupby('product_id')['tn'].shift(lag)\n",
    "\n",
    "# Reemplazar valores faltantes con 0\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Filtrar los datos hasta 2019-12-01 para entrenamiento\n",
    "train_data = data[data['periodo'] <= '2019-12-01']\n",
    "\n",
    "# Definir las características y el target\n",
    "features = ['product_id','customer_id','year', 'month', 'cust_request_qty'] + [f'tn_lag_{lag}' for lag in lags]\n",
    "target = 'tn'\n",
    "\n",
    "X = train_data[features]\n",
    "y = train_data[target]\n",
    "\n",
    "# Normalizar características\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar un modelo de regresión lineal para cada product_id\n",
    "product_ids = data['product_id'].unique()\n",
    "regressions = {}\n",
    "coefs = {}\n",
    "for pid in product_ids:\n",
    "    X_pid = train_data[train_data['product_id'] == pid][features]\n",
    "    y_pid = train_data[train_data['product_id'] == pid][target]\n",
    "    X_pid = scaler.fit_transform(X_pid)\n",
    "    regression = LinearRegression()\n",
    "    regression.fit(X_pid, y_pid)\n",
    "    regressions[pid] = regression\n",
    "    coefs[pid] = (regression.coef_, regression.intercept_)\n",
    "\n",
    "# Crear el DataFrame para las predicciones de febrero de 2020\n",
    "unique_product_ids = data2['product_id'].unique()\n",
    "unique_customer_ids = data2['customer_id'].unique()\n",
    "prediction_data = pd.DataFrame([(pid, cid) for pid in unique_product_ids for cid in unique_customer_ids], columns=['product_id', 'customer_id'])\n",
    "\n",
    "# Añadir las columnas necesarias para las características adicionales\n",
    "prediction_data['year'] = 2020\n",
    "prediction_data['month'] = 2\n",
    "\n",
    "# Para 'cust_request_qty', usamos el promedio de solicitudes por combinación de product_id y customer_id\n",
    "cust_request_qty_means = data.groupby(['product_id', 'customer_id'])['cust_request_qty'].mean().reset_index()\n",
    "prediction_data = prediction_data.merge(cust_request_qty_means, on=['product_id', 'customer_id'], how='left')\n",
    "\n",
    "# Reemplazar valores faltantes con 0\n",
    "prediction_data.fillna(0, inplace=True)\n",
    "\n",
    "# Agregar lags para 'tn' en el conjunto de datos de predicción\n",
    "for lag in lags:\n",
    "    lag_col = f'tn_lag_{lag}'\n",
    "    prediction_data[lag_col] = 0\n",
    "    for pid in unique_product_ids:\n",
    "        mask = prediction_data['product_id'] == pid\n",
    "        if lag_col in data.columns:\n",
    "            data_lags = data.loc[data['product_id'] == pid, lag_col].values\n",
    "            pred_lags = prediction_data.loc[mask, lag_col]\n",
    "            prediction_data.loc[mask, lag_col] = data_lags[-len(pred_lags):] if len(data_lags) >= len(pred_lags) else np.pad(data_lags, (len(pred_lags) - len(data_lags), 0), 'constant')\n",
    "\n",
    "# Predicciones usando regresión lineal para cada product_id\n",
    "for pid, regression in regressions.items():\n",
    "    X_pid_pred = prediction_data[prediction_data['product_id'] == pid][features]\n",
    "    X_pid_pred = scaler.transform(X_pid_pred)\n",
    "    prediction_data.loc[prediction_data['product_id'] == pid, 'tn'] = regression.predict(X_pid_pred)\n",
    "\n",
    "# Ajustar los hiperparámetros del modelo LightGBM\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 50],\n",
    "    'min_data_in_leaf': [20, 50, 100],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 500]\n",
    "}\n",
    "lgb_model = LGBMRegressor()\n",
    "grid = GridSearchCV(lgb_model, param_grid, cv=3, scoring='neg_mean_squared_error', verbose=1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones finales usando el mejor modelo LightGBM\n",
    "best_model = grid.best_estimator_\n",
    "X_pred = scaler.transform(prediction_data[features])\n",
    "prediction_data['transformed_tn'] = best_model.predict(X_pred)\n",
    "\n",
    "# Invertir la transformación para obtener los valores originales\n",
    "for pid, (coef, intercept) in coefs.items():\n",
    "    mask = prediction_data['product_id'] == pid\n",
    "    prediction_data.loc[mask, 'tn'] = prediction_data.loc[mask, 'transformed_tn'] * coef[0] + intercept\n",
    "\n",
    "# Agrupar por product_id y sumar las predicciones de tn\n",
    "grouped_predictions = prediction_data.groupby('product_id')['tn'].sum().reset_index()\n",
    "\n",
    "# Añadir la columna de periodo\n",
    "grouped_predictions['periodo'] = '202002'\n",
    "\n",
    "# Seleccionar columnas y guardar en CSV\n",
    "output = grouped_predictions[['product_id', 'tn']]\n",
    "output.to_csv('predicciones_feb_2020.csv', index=False)\n",
    "\n",
    "print(\"Predicciones guardadas en 'predicciones_feb_2020.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "761b7033-1a89-4d55-b392-1de71dc82f1b",
     "showTitle": false,
     "title": ""
    },
    "id": "wszs4lO2xNVZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data = data2\n",
    "\n",
    "# Crear características adicionales (features)\n",
    "data['year'] = data['periodo'].dt.year\n",
    "data['month'] = data['periodo'].dt.month\n",
    "\n",
    "# Agregar lags para 'tn' en el conjunto de datos\n",
    "lags = [1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
    "for lag in lags:\n",
    "    data[f'tn_lag_{lag}'] = data.groupby(['product_id', 'customer_id'])['tn'].shift(lag)\n",
    "\n",
    "# Calcular deltas (diferencias entre lags)\n",
    "for lag in range(1, len(lags)):\n",
    "    data[f'delta_tn_lag_{lags[lag]}'] = data[f'tn_lag_{lags[lag]}'] - data[f'tn_lag_{lags[lag-1]}']\n",
    "\n",
    "# Reemplazar valores faltantes con 0\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "# Filtrar los datos hasta 2019-12-01 para entrenamiento\n",
    "train_data = data[data['periodo'] <= '2019-12-01']\n",
    "\n",
    "# Definir las características y el target\n",
    "features = ['product_id', 'customer_id', 'year', 'month', 'cust_request_qty'] + [f'tn_lag_{lag}' for lag in lags] + [f'delta_tn_lag_{lags[lag]}' for lag in range(1, len(lags))]\n",
    "target = 'tn'\n",
    "\n",
    "# Normalizar las características por product_id, customer_id y periodo\n",
    "def normalize(group):\n",
    "    return (group - group.mean()) / group.std()\n",
    "\n",
    "for feature in features:\n",
    "    if feature not in ['product_id', 'customer_id', 'year', 'month']:\n",
    "        train_data[feature] = train_data.groupby(['product_id', 'customer_id', 'year', 'month'])[feature].transform(normalize)\n",
    "\n",
    "X = train_data[features]\n",
    "y = train_data[target]\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo LightGBM\n",
    "model = LGBMRegressor()\n",
    "model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
    "\n",
    "# Crear el DataFrame para las predicciones de febrero de 2020\n",
    "# Usamos todas las combinaciones únicas de product_id y customer_id en el dataset\n",
    "unique_product_ids = data['product_id'].unique()\n",
    "unique_customer_ids = data['customer_id'].unique()\n",
    "prediction_data = pd.DataFrame([(pid, cid) for pid in unique_product_ids for cid in unique_customer_ids], columns=['product_id', 'customer_id'])\n",
    "\n",
    "# Añadir las columnas necesarias\n",
    "prediction_data['year'] = 2020\n",
    "prediction_data['month'] = 2\n",
    "\n",
    "# Para 'cust_request_qty', usamos el promedio de solicitudes por combinación de product_id y customer_id\n",
    "cust_request_qty_means = data.groupby(['product_id', 'customer_id'])['cust_request_qty'].mean().reset_index()\n",
    "prediction_data = prediction_data.merge(cust_request_qty_means, on=['product_id', 'customer_id'], how='left')\n",
    "\n",
    "# Rellenar NaNs en 'cust_request_qty' con 0 si no hay datos históricos para esa combinación\n",
    "prediction_data['cust_request_qty'] = prediction_data['cust_request_qty'].fillna(0)\n",
    "\n",
    "# Agregar lags para 'tn' y deltas en el conjunto de datos de predicción\n",
    "for lag in lags:\n",
    "    lag_col = f'tn_lag_{lag}'\n",
    "    delta_lag_col = f'delta_tn_lag_{lag}'\n",
    "    prediction_data[lag_col] = 0\n",
    "    if lag != lags[0]:  # No hay delta para el primer lag\n",
    "        prediction_data[delta_lag_col] = 0\n",
    "    for pid in unique_product_ids:\n",
    "        for cid in unique_customer_ids:\n",
    "            mask = (prediction_data['product_id'] == pid) & (prediction_data['customer_id'] == cid)\n",
    "            if lag_col in data.columns:\n",
    "                data_lags = data.loc[(data['product_id'] == pid) & (data['customer_id'] == cid), lag_col].values\n",
    "                pred_lags = prediction_data.loc[mask, lag_col]\n",
    "                if len(data_lags) >= len(pred_lags):\n",
    "                    prediction_data.loc[mask, lag_col] = data_lags[-len(pred_lags):]\n",
    "                else:\n",
    "                    prediction_data.loc[mask, lag_col] = np.pad(data_lags, (len(pred_lags) - len(data_lags), 0), 'constant')\n",
    "            if lag != lags[0] and delta_lag_col in data.columns:\n",
    "                data_deltas = data.loc[(data['product_id'] == pid) & (data['customer_id'] == cid), delta_lag_col].values\n",
    "                pred_deltas = prediction_data.loc[mask, delta_lag_col]\n",
    "                if len(data_deltas) >= len(pred_deltas):\n",
    "                    prediction_data.loc[mask, delta_lag_col] = data_deltas[-len(pred_deltas):]\n",
    "                else:\n",
    "                    prediction_data.loc[mask, delta_lag_col] = np.pad(data_deltas, (len(pred_deltas) - len(data_deltas), 0), 'constant')\n",
    "\n",
    "# Normalizar las características por product_id, customer_id y periodo en el conjunto de predicción\n",
    "for feature in features:\n",
    "    if feature not in ['product_id', 'customer_id', 'year', 'month']:\n",
    "        prediction_data[feature] = prediction_data.groupby(['product_id', 'customer_id', 'year', 'month'])[feature].transform(normalize)\n",
    "\n",
    "# Hacer predicciones\n",
    "X_pred = prediction_data[features]\n",
    "prediction_data['tn'] = model.predict(X_pred)\n",
    "\n",
    "# Agrupar por product_id y sumar las predicciones de tn\n",
    "grouped_predictions = prediction_data.groupby('product_id')['tn'].sum().reset_index()\n",
    "\n",
    "# Añadir la columna de periodo\n",
    "grouped_predictions['periodo'] = '202002'\n",
    "\n",
    "# Seleccionar columnas y guardar en CSV\n",
    "output = grouped_predictions[['product_id', 'tn']]\n",
    "output.to_csv('predicciones_feb_2020.csv', index=False)\n",
    "\n",
    "print(\"Predicciones guardadas en 'predicciones_feb_2020.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae0adf4e-6487-4f76-a102-5bfaa623e984",
     "showTitle": false,
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hk9HWd34vB3Z",
    "outputId": "24f68409-f6d2-4325-ae65-2b288886cc06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.657033 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12495\n",
      "[LightGBM] [Info] Number of data points in the train set: 1839369, number of used features: 49\n",
      "[LightGBM] [Info] Start training from score 0.352071\n",
      "Predicciones guardadas en 'predicciones_feb_2020.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data = data2\n",
    "\n",
    "# Crear características adicionales (features)\n",
    "data['year'] = data['periodo'].dt.year\n",
    "data['month'] = data['periodo'].dt.month\n",
    "\n",
    "# Calcular deltas (diferencias de tn entre meses)\n",
    "data['delta_tn'] = data.groupby('product_id')['tn'].diff()\n",
    "\n",
    "# Reemplazar valores faltantes con 0 para deltas\n",
    "data['delta_tn'] = data['delta_tn'].fillna(0)\n",
    "\n",
    "# Filtrar los datos hasta 2019-12-01 para entrenamiento\n",
    "train_data = data[data['periodo'] <= '2019-12-01']\n",
    "\n",
    "# Agregar lags para 'tn' en el conjunto de datos\n",
    "lags = [1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
    "for lag in lags:\n",
    "    train_data[f'tn_lag_{lag}'] = train_data.groupby('product_id')['tn'].shift(lag)\n",
    "    train_data[f'delta_tn_lag_{lag}'] = train_data.groupby('product_id')['delta_tn'].shift(lag)\n",
    "\n",
    "# Rellenar NaNs con 0 en los lags\n",
    "train_data.fillna(0, inplace=True)\n",
    "\n",
    "# Definir las características y el target\n",
    "features = ['product_id', 'customer_id', 'year', 'month', 'cust_request_qty'] + [f'tn_lag_{lag}' for lag in lags] + [f'delta_tn_lag_{lag}' for lag in lags]\n",
    "target = 'tn'\n",
    "\n",
    "# Normalizar las características por product_id\n",
    "for feature in features:\n",
    "    if feature not in ['product_id', 'customer_id']:\n",
    "        train_data[feature] = train_data.groupby('product_id')[feature].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "X = train_data[features]\n",
    "y = train_data[target]\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo LightGBM\n",
    "model = LGBMRegressor()\n",
    "model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
    "\n",
    "# Crear el DataFrame para las predicciones de febrero de 2020\n",
    "# Usamos todas las combinaciones únicas de product_id y customer_id en el dataset\n",
    "unique_product_ids = data['product_id'].unique()\n",
    "unique_customer_ids = data['customer_id'].unique()\n",
    "prediction_data = pd.DataFrame([(pid, cid) for pid in unique_product_ids for cid in unique_customer_ids], columns=['product_id', 'customer_id'])\n",
    "\n",
    "# Añadir las columnas necesarias\n",
    "prediction_data['year'] = 2020\n",
    "prediction_data['month'] = 2\n",
    "\n",
    "# Para 'cust_request_qty', usamos el promedio de solicitudes por combinación de product_id y customer_id\n",
    "cust_request_qty_means = data.groupby(['product_id', 'customer_id'])['cust_request_qty'].mean().reset_index()\n",
    "prediction_data = prediction_data.merge(cust_request_qty_means, on=['product_id', 'customer_id'], how='left')\n",
    "\n",
    "# Rellenar NaNs en 'cust_request_qty' con 0 si no hay datos históricos para esa combinación\n",
    "prediction_data['cust_request_qty'] = prediction_data['cust_request_qty'].fillna(0)\n",
    "\n",
    "# Agregar lags para 'tn' y 'delta_tn' en el conjunto de datos de predicción\n",
    "for lag in lags:\n",
    "    prediction_data[f'tn_lag_{lag}'] = 0\n",
    "    prediction_data[f'delta_tn_lag_{lag}'] = 0\n",
    "    for pid in unique_product_ids:\n",
    "        mask = prediction_data['product_id'] == pid\n",
    "        if f'tn_lag_{lag}' in data.columns:\n",
    "            data_lags = data.loc[data['product_id'] == pid, f'tn_lag_{lag}'].values\n",
    "            pred_lags = prediction_data.loc[mask, f'tn_lag_{lag}']\n",
    "            prediction_data.loc[mask, f'tn_lag_{lag}'] = data_lags[-len(pred_lags):] if len(data_lags) >= len(pred_lags) else np.pad(data_lags, (len(pred_lags) - len(data_lags), 0), 'constant')\n",
    "        if f'delta_tn_lag_{lag}' in data.columns:\n",
    "            data_deltas = data.loc[data['product_id'] == pid, f'delta_tn_lag_{lag}'].values\n",
    "            pred_deltas = prediction_data.loc[mask, f'delta_tn_lag_{lag}']\n",
    "            prediction_data.loc[mask, f'delta_tn_lag_{lag}'] = data_deltas[-len(pred_deltas):] if len(data_deltas) >= len(pred_deltas) else np.pad(data_deltas, (len(pred_deltas) - len(data_deltas), 0), 'constant')\n",
    "\n",
    "# Normalizar las características por product_id en el conjunto de predicción\n",
    "for feature in features:\n",
    "    if feature not in ['product_id', 'customer_id']:\n",
    "        prediction_data[feature] = prediction_data.groupby('product_id')[feature].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "# Hacer predicciones\n",
    "X_pred = prediction_data[features]\n",
    "prediction_data['tn'] = model.predict(X_pred)\n",
    "\n",
    "# Agrupar por product_id y sumar las predicciones de tn\n",
    "grouped_predictions = prediction_data.groupby('product_id')['tn'].sum().reset_index()\n",
    "\n",
    "# Añadir la columna de periodo\n",
    "grouped_predictions['periodo'] = '202002'\n",
    "\n",
    "# Seleccionar columnas y guardar en CSV\n",
    "output = grouped_predictions[['product_id', 'tn']]\n",
    "output.to_csv('predicciones_feb_2020.csv', index=False)\n",
    "\n",
    "print(\"Predicciones guardadas en 'predicciones_feb_2020.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46e72248-f58c-4115-80cf-ef709d88d433",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# LightGBM VF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15a63011-dc4f-469e-8d10-ab1ac62d97e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data=data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "965d8b96-4fde-46a5-aecc-f2d91db89a92",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Sin hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdd645ad-0192-4638-84fb-6167d422c8a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39684b39f690402082b49ab35e04e75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-1787845986750664>:90\u001b[0m\n",
       "\u001b[1;32m     83\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n",
       "\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_leaves\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m31\u001b[39m, \u001b[38;5;241m50\u001b[39m],\n",
       "\u001b[1;32m     85\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_data_in_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m20\u001b[39m],\n",
       "\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.1\u001b[39m],\n",
       "\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m500\u001b[39m]\n",
       "\u001b[1;32m     88\u001b[0m }\n",
       "\u001b[1;32m     89\u001b[0m lgb_model \u001b[38;5;241m=\u001b[39m LGBMRegressor()\n",
       "\u001b[0;32m---> 90\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(lgb_model, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
       "\u001b[1;32m     91\u001b[0m grid\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
       "\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Hacer predicciones finales usando el mejor modelo LightGBM\u001b[39;00m\n",
       "\n",
       "\u001b[0;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\nFile \u001b[0;32m<command-1787845986750664>:90\u001b[0m\n\u001b[1;32m     83\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_leaves\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m31\u001b[39m, \u001b[38;5;241m50\u001b[39m],\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_data_in_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m20\u001b[39m],\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.1\u001b[39m],\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m500\u001b[39m]\n\u001b[1;32m     88\u001b[0m }\n\u001b[1;32m     89\u001b[0m lgb_model \u001b[38;5;241m=\u001b[39m LGBMRegressor()\n\u001b[0;32m---> 90\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(lgb_model, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     91\u001b[0m grid\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Hacer predicciones finales usando el mejor modelo LightGBM\u001b[39;00m\n\n\u001b[0;31mNameError\u001b[0m: name 'GridSearchCV' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'GridSearchCV' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Supongamos que 'data' es tu DataFrame original con los datos\n",
    "Crear características adicionales (features)\n",
    "data['year'] = data['periodo'].dt.year\n",
    "data['month'] = data['periodo'].dt.month\n",
    "\n",
    "Calcular deltas (diferencias de tn entre meses)\n",
    "data['delta_tn'] = data.groupby('product_id')['tn'].diff()\n",
    "\n",
    "Reemplazar valores faltantes con 0 para deltas\n",
    "data['delta_tn'] = data['delta_tn'].fillna(0)\n",
    "\n",
    "Filtrar los datos hasta 2019-10-31 para entrenamiento\n",
    "train_data = data[data['periodo'] <= '2019-10-31'].copy()\n",
    "\n",
    "Definir lags y delta lags personalizados\n",
    "lags = [1, 2, 3,4,5, 6,7,8, 9,10,11, 12,13,14,15,16,17, 18,19,20,21,22,23,24] # Puedes ajustar esta lista según tus necesidades\n",
    "delta_lags = [1, 2, 3,4,5, 6,7,8, 9,10,11, 12,13,14,15,16,17, 18,19,20,21,22,23,24] # También puedes ajustar esta lista según tus necesidades\n",
    "\n",
    "Agregar lags para 'tn' y delta lags\n",
    "for lag in lags:\n",
    "train_data[f'tn_lag_{lag}'] = train_data.groupby('product_id')['tn'].shift(lag)\n",
    "\n",
    "for delta_lag in delta_lags:\n",
    "train_data[f'delta_tn_lag_{delta_lag}'] = train_data.groupby('product_id')['delta_tn'].shift(delta_lag)\n",
    "\n",
    "Rellenar NaNs con 0 en los lags y delta lags\n",
    "train_data.fillna(0, inplace=True)\n",
    "\n",
    "Definir las características y el target\n",
    "features = ['product_id', 'customer_id', 'year', 'month', 'cust_request_qty'] + [f'tn_lag_{lag}' for lag in lags] + [f'delta_tn_lag_{delta_lag}' for delta_lag in delta_lags]\n",
    "target = 'tn'\n",
    "\n",
    "Normalizar las características por product_id\n",
    "for feature in features:\n",
    "if feature not in ['product_id', 'customer_id']:\n",
    "train_data[feature] = train_data.groupby('product_id')[feature].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "X_train = train_data[train_data['periodo'] <= '2019-10-31'][features]\n",
    "y_train = train_data[train_data['periodo'] <= '2019-10-31'][target]\n",
    "\n",
    "Entrenar el modelo LightGBM\n",
    "model = LGBMRegressor()\n",
    "model.fit(X_train, y_train, eval_metric='mae')\n",
    "\n",
    "Crear el DataFrame para las predicciones de diciembre de 2019\n",
    "unique_product_ids = data['product_id'].unique()\n",
    "unique_customer_ids = data['customer_id'].unique()\n",
    "prediction_data = pd.DataFrame([(pid, cid) for pid in unique_product_ids for cid in unique_customer_ids], columns=['product_id', 'customer_id'])\n",
    "\n",
    "Añadir las columnas necesarias\n",
    "prediction_data['year'] = 2019\n",
    "prediction_data['month'] = 12\n",
    "\n",
    "Para 'cust_request_qty', usamos el promedio de solicitudes por combinación de product_id y customer_id\n",
    "cust_request_qty_means = data.groupby(['product_id', 'customer_id'])['cust_request_qty'].mean().reset_index()\n",
    "prediction_data = prediction_data.merge(cust_request_qty_means, on=['product_id', 'customer_id'], how='left')\n",
    "\n",
    "Rellenar NaNs en 'cust_request_qty' con 0 si no hay datos históricos para esa combinación\n",
    "prediction_data['cust_request_qty'] = prediction_data['cust_request_qty'].fillna(0)\n",
    "\n",
    "Agregar lags para 'tn' y 'delta_tn' en el conjunto de datos de predicción\n",
    "for lag in lags:\n",
    "prediction_data[f'tn_lag_{lag}'] = 0\n",
    "for pid in unique_product_ids:\n",
    "mask = prediction_data['product_id'] == pid\n",
    "if f'tn_lag_{lag}' in train_data.columns:\n",
    "data_lags = train_data.loc[train_data['product_id'] == pid, f'tn_lag_{lag}'].values\n",
    "pred_lags = prediction_data.loc[mask, f'tn_lag_{lag}']\n",
    "prediction_data.loc[mask, f'tn_lag_{lag}'] = data_lags[-len(pred_lags):] if len(data_lags) >= len(pred_lags) else np.pad(data_lags, (len(pred_lags)-len(data_lags), 0), 'constant')\n",
    "\n",
    "for delta_lag in delta_lags:\n",
    "prediction_data[f'delta_tn_lag_{delta_lag}'] = 0\n",
    "for pid in unique_product_ids:\n",
    "mask = prediction_data['product_id'] == pid\n",
    "if f'delta_tn_lag_{delta_lag}' in train_data.columns:\n",
    "data_deltas = train_data.loc[train_data['product_id'] == pid, f'delta_tn_lag_{delta_lag}'].values\n",
    "pred_deltas = prediction_data.loc[mask, f'delta_tn_lag_{delta_lag}']\n",
    "prediction_data.loc[mask, f'delta_tn_lag_{delta_lag}'] = data_deltas[-len(pred_deltas):] if len(data_deltas) >= len(pred_deltas) else np.pad(data_deltas, (len(pred_deltas)-len(data_deltas), 0), 'constant')\n",
    "\n",
    "Normalizar las características por product_id en el conjunto de predicción\n",
    "for feature in features:\n",
    "if feature not in ['product_id', 'customer_id', 'periodo']:\n",
    "prediction_data[feature] = prediction_data.groupby('product_id')[feature].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "Hacer predicciones\n",
    "X_pred = prediction_data[features]\n",
    "prediction_data['tn'] = model.predict(X_pred)\n",
    "\n",
    "Agrupar por product_id y sumar las predicciones de tn\n",
    "grouped_predictions = prediction_data.groupby('product_id')['tn'].sum().reset_index()\n",
    "\n",
    "Añadir la columna de periodo\n",
    "grouped_predictions['periodo'] = '201912'\n",
    "\n",
    "Seleccionar columnas y guardar en CSV\n",
    "output = grouped_predictions[['product_id', 'tn']]\n",
    "output.to_csv('/Workspace/Users/mibassan@ab-inbev.com/Mica/predicciones_dic_2019.csv', index=False)\n",
    "\n",
    "Comparar las predicciones con los datos reales de diciembre de 2019\n",
    "real_data_dec_2019 = data[data['periodo'] == '2019-12-01'][['product_id', 'tn']].groupby('product_id').sum().reset_index()\n",
    "comparison = pd.merge(output, real_data_dec_2019, on='product_id', suffixes=('_pred', '_real'))\n",
    "\n",
    "Después de generar las predicciones y antes de calcular el MAE, añade estas líneas:\n",
    "print(\"Predicciones:\")\n",
    "print(output) # Assuming you meant to print the output here\n",
    "\n",
    "Comparar las predicciones con los datos reales de diciembre de 2019\n",
    "print(\"Datos reales para diciembre de 2019:\")\n",
    "print(real_data_dec_2019)\n",
    "\n",
    "Calcular el error absoluto medio (MAE)\n",
    "mae = np.mean(np.abs(comparison['tn_pred'] - comparison['tn_real']))\n",
    "print(f\"Error absoluto medio (MAE) de las predicciones para diciembre de 2019: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "052954d4-a5c7-4e19-8313-974468ecfeef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Con Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4801a0ad-5988-46c6-8d71-292e1d5dad77",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Supongamos que 'data' es tu DataFrame original con los datos\n",
    "# Crear características adicionales (features)\n",
    "data['year'] = data['periodo'].dt.year\n",
    "data['month'] = data['periodo'].dt.month\n",
    "data['quarter'] = data['periodo'].dt.quarter  # Nueva característica de trimestre\n",
    "\n",
    "# Calcular deltas (diferencias de tn entre meses)\n",
    "data['delta_tn'] = data.groupby('product_id')['tn'].diff()\n",
    "\n",
    "# Reemplazar valores faltantes con 0 para deltas\n",
    "data['delta_tn'] = data['delta_tn'].fillna(0)\n",
    "\n",
    "# Filtrar los datos hasta 2019-10-31 para entrenamiento\n",
    "train_data = data[data['periodo'] <= '2019-10-31'].copy()\n",
    "\n",
    "# Definir lags y delta lags personalizados\n",
    "lags = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
    "delta_lags = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
    "\n",
    "# Agregar lags para 'tn' y delta lags\n",
    "for lag in lags:\n",
    "    train_data[f'tn_lag_{lag}'] = train_data.groupby('product_id')['tn'].shift(lag)\n",
    "\n",
    "for delta_lag in delta_lags:\n",
    "    train_data[f'delta_tn_lag_{delta_lag}'] = train_data.groupby('product_id')['delta_tn'].shift(delta_lag)\n",
    "\n",
    "# Rellenar NaNs con 0 en los lags y delta lags\n",
    "train_data.fillna(0, inplace=True)\n",
    "\n",
    "# Definir las características y el target\n",
    "features = ['product_id', 'customer_id', 'year', 'month', 'quarter', 'cust_request_qty'] + [f'tn_lag_{lag}' for lag in lags] + [f'delta_tn_lag_{delta_lag}' for delta_lag in delta_lags]\n",
    "target = 'tn'\n",
    "\n",
    "# Normalizar las características por product_id\n",
    "for feature in features:\n",
    "    if feature not in ['product_id', 'customer_id', 'periodo']:\n",
    "        train_data[feature] = train_data.groupby('product_id')[feature].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "# Separar los datos de entrenamiento\n",
    "X_train = train_data[train_data['periodo'] <= '2019-10-31'][features]\n",
    "y_train = train_data[train_data['periodo'] <= '2019-10-31'][target]\n",
    "\n",
    "# Definir los parámetros a ajustar\n",
    "param_grid = {\n",
    "    'num_leaves': [20, 30, 40],\n",
    "    'learning_rate': [0.05, 0.1, 0.15],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'reg_alpha': [0.1, 0.5],\n",
    "    'reg_lambda': [0.1, 0.5]\n",
    "}\n",
    "\n",
    "# Inicializar el modelo con LightGBM\n",
    "model = LGBMRegressor()\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_absolute_error', verbose=2)\n",
    "\n",
    "# Ejecutar la búsqueda de cuadrícula en los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores parámetros y el mejor score\n",
    "print(\"Mejores parámetros encontrados:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"Mejor score encontrado:\")\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "# Asignar el modelo con los mejores parámetros\n",
    "model = grid_search.best_estimator_\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train, eval_metric='mae')\n",
    "\n",
    "# Crear el DataFrame para las predicciones de diciembre de 2019\n",
    "unique_product_ids = data['product_id'].unique()\n",
    "unique_customer_ids = data['customer_id'].unique()\n",
    "prediction_data = pd.DataFrame([(pid, cid) for pid in unique_product_ids for cid in unique_customer_ids], columns=['product_id', 'customer_id'])\n",
    "\n",
    "# Añadir las columnas necesarias\n",
    "prediction_data['year'] = 2019\n",
    "prediction_data['month'] = 12\n",
    "prediction_data['quarter'] = 4  # Trimestre 4 para diciembre\n",
    "\n",
    "# Para 'cust_request_qty', usamos el promedio de solicitudes por combinación de product_id y customer_id\n",
    "cust_request_qty_means = data.groupby(['product_id', 'customer_id'])['cust_request_qty'].mean().reset_index()\n",
    "prediction_data = prediction_data.merge(cust_request_qty_means, on=['product_id', 'customer_id'], how='left')\n",
    "\n",
    "# Rellenar NaNs en 'cust_request_qty' con 0 si no hay datos históricos para esa combinación\n",
    "prediction_data['cust_request_qty'] = prediction_data['cust_request_qty'].fillna(0)\n",
    "\n",
    "# Agregar lags para 'tn' y 'delta_tn' en el conjunto de datos de predicción\n",
    "for lag in lags:\n",
    "    prediction_data[f'tn_lag_{lag}'] = 0\n",
    "    for pid in unique_product_ids:\n",
    "        mask = prediction_data['product_id'] == pid\n",
    "        if f'tn_lag_{lag}' in train_data.columns:\n",
    "            data_lags = train_data.loc[train_data['product_id'] == pid, f'tn_lag_{lag}'].values\n",
    "            pred_lags = prediction_data.loc[mask, f'tn_lag_{lag}']\n",
    "            prediction_data.loc[mask, f'tn_lag_{lag}'] = data_lags[-len(pred_lags):] if len(data_lags) >= len(pred_lags) else np.pad(data_lags, (len(pred_lags)-len(data_lags), 0), 'constant')\n",
    "\n",
    "for delta_lag in delta_lags:\n",
    "    prediction_data[f'delta_tn_lag_{delta_lag}'] = 0\n",
    "    for pid in unique_product_ids:\n",
    "        mask = prediction_data['product_id'] == pid\n",
    "        if f'delta_tn_lag_{delta_lag}' in train_data.columns:\n",
    "            data_deltas = train_data.loc[train_data['product_id'] == pid, f'delta_tn_lag_{delta_lag}'].values\n",
    "            pred_deltas = prediction_data.loc[mask, f'delta_tn_lag_{delta_lag}']\n",
    "            prediction_data.loc[mask, f'delta_tn_lag_{delta_lag}'] = data_deltas[-len(pred_deltas):] if len(data_deltas) >= len(pred_deltas) else np.pad(data_deltas, (len(pred_deltas)-len(data_deltas), 0), 'constant')\n",
    "\n",
    "# Normalizar las características por product_id en el conjunto de predicción\n",
    "for feature in features:\n",
    "    if feature not in ['product_id', 'customer_id', 'periodo']:\n",
    "        prediction_data[feature] = prediction_data.groupby('product_id')[feature].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "# Hacer predicciones\n",
    "X_pred = prediction_data[features]\n",
    "prediction_data['tn'] = model.predict(X_pred)\n",
    "\n",
    "# Agrupar por product_id y sumar las predicciones de tn\n",
    "grouped_predictions = prediction_data.groupby('product_id')['tn'].sum().reset_index()\n",
    "\n",
    "# Añadir la columna de periodo\n",
    "grouped_predictions['periodo'] = '201912'\n",
    "\n",
    "# Seleccionar columnas y guardar en CSV\n",
    "output = grouped_predictions[['product_id', 'tn']]\n",
    "output.to_csv('/Workspace/Users/mibassan@ab-inbev.com/Mica/predicciones_dic_2019.csv', index=False)\n",
    "\n",
    "# Comparar las predicciones con los datos reales de diciembre de 2019\n",
    "real_data_dec_2019 = data[data['periodo'] == '2019-12-01'][['product_id', 'tn']].groupby('product_id').sum().reset_index()\n",
    "comparison = pd.merge(output, real_data_dec_2019, on='product_id', suffixes=('_pred', '_real'))\n",
    "\n",
    "# Imprimir las predicciones\n",
    "print(\"Predicciones:\")\n",
    "print(output)\n",
    "\n",
    "# Imprimir datos reales\n",
    "print(\"Datos reales para diciembre de 2019:\")\n",
    "print(real_data_dec_2019)\n",
    "\n",
    "# Calcular el error absoluto medio (MAE)\n",
    "mae = np.mean(np.abs(comparison['tn_pred'] - comparison['tn_real']))\n",
    "print(f\"Error absoluto medio (MAE) de las predicciones para diciembre de 2019: {mae}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "LigthgbmVF",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
