{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:25px;color:#34656d;font-family:'Comic Sans MS';text-align:center;border-radius:5px;\">\n",
    "<strong>LightGBM - Clase 5 - V1.0</strong></p> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:25px;color:#34656d;font-family:'Comic Sans MS';text-align:center;border-radius:5px;\">\n",
    "<strong>______________________</strong></p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   periodo  customer_id  product_id  plan_precios_cuidados  cust_request_qty  cust_request_tn       tn\n",
      "0   201701        10234       20524                      0                 2          0.05300  0.05300\n",
      "1   201701        10032       20524                      0                 1          0.13628  0.13628\n",
      "2   201701        10217       20524                      0                 1          0.03028  0.03028\n",
      "3   201701        10125       20524                      0                 1          0.02271  0.02271\n",
      "4   201701        10012       20524                      0                11          1.54452  1.54452\n",
      "   product_id\n",
      "0       20001\n",
      "1       20002\n",
      "2       20003\n",
      "3       20004\n",
      "4       20005\n"
     ]
    }
   ],
   "source": [
    "# Lee el archivo como un DataFrame\n",
    "data_full  = pd.read_csv('data/sell-in.csv', delimiter='\\t')\n",
    "df_pid_validos  = pd.read_csv('data/productos_a_predecir.txt')\n",
    "\n",
    "# Ajustar el ancho máximo de las columnas\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Ajustar el ancho máximo de la visualización\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Muestra las primeras filas del DataFrame\n",
    "print(data_full.head())\n",
    "data_full.info()\n",
    "print(df_pid_validos.head())\n",
    "\n",
    "#  Si tomo el archivo desde el buket de la maquina virtual del laboratorio\n",
    "#\n",
    "# Ruta del archivo ventas comprimido\n",
    "# file_path = 'data/sell-in.txt.gz'\n",
    "\n",
    "# Abre el archivo comprimido\n",
    "#with gzip.open(file_path, 'rt') as f:\n",
    "#    # Lee el archivo CSV usando pandas, especificando que el separador es un tabulador\n",
    "#    data_full = pd.read_csv(f, sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La lista product_ids_validos tiene 780 registros.\n"
     ]
    }
   ],
   "source": [
    "# Armado de la lista de productos validos a predecir para el periodo\n",
    "product_ids_validos = df_pid_validos['product_id'].tolist()\n",
    "\n",
    "# Ver cuántos registros tiene la lista\n",
    "num_registros = len(product_ids_validos)\n",
    "print(f\"La lista product_ids_validos tiene {num_registros} registros.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame filtrado tiene 2293481 registros.\n",
      "Todos los product_id en el DataFrame filtrado son válidos.\n",
      "Número de registros por product_id en el DataFrame filtrado:\n",
      "product_id\n",
      "20111    7973\n",
      "20122    7950\n",
      "20120    7537\n",
      "20326    7397\n",
      "20132    7199\n",
      "         ... \n",
      "21267      67\n",
      "21252      67\n",
      "21276      64\n",
      "20886      63\n",
      "20953      62\n",
      "Name: count, Length: 780, dtype: int64\n",
      "   periodo  customer_id  product_id  plan_precios_cuidados  cust_request_qty  cust_request_tn       tn\n",
      "0   201701        10234       20524                      0                 2          0.05300  0.05300\n",
      "1   201701        10032       20524                      0                 1          0.13628  0.13628\n",
      "2   201701        10217       20524                      0                 1          0.03028  0.03028\n",
      "3   201701        10125       20524                      0                 1          0.02271  0.02271\n",
      "4   201701        10012       20524                      0                11          1.54452  1.54452\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2293481 entries, 0 to 2945817\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   periodo                int64  \n",
      " 1   customer_id            int64  \n",
      " 2   product_id             int64  \n",
      " 3   plan_precios_cuidados  int64  \n",
      " 4   cust_request_qty       int64  \n",
      " 5   cust_request_tn        float64\n",
      " 6   tn                     float64\n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 140.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Filtrar el DataFrame original para quedarse solo con los product_id válidos\n",
    "data = data_full[data_full['product_id'].isin(product_ids_validos)]\n",
    "\n",
    "# Ver cuántos registros tiene el DataFrame filtrado\n",
    "num_registros_filtrados = len(data)\n",
    "print(f\"El DataFrame filtrado tiene {num_registros_filtrados} registros.\")\n",
    "\n",
    "# Verificar que todos los product_id en el DataFrame filtrado están en la lista de productos válidos\n",
    "productos_unicos_filtrados = data['product_id'].unique()\n",
    "productos_invalidos = [pid for pid in productos_unicos_filtrados if pid not in product_ids_validos]\n",
    "\n",
    "if len(productos_invalidos) == 0:\n",
    "    print(\"Todos los product_id en el DataFrame filtrado son válidos.\")\n",
    "else:\n",
    "    print(f\"Se encontraron productos no válidos en el DataFrame filtrado: {productos_invalidos}\")\n",
    "\n",
    "# (Opcional) Ver cuántos registros hay por cada product_id\n",
    "registros_por_producto = data['product_id'].value_counts()\n",
    "print(\"Número de registros por product_id en el DataFrame filtrado:\")\n",
    "print(registros_por_producto)\n",
    "\n",
    "# Ver como esta el data frame\n",
    "print(data.head())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 1: Preparación de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hbasilio\\AppData\\Local\\Temp\\ipykernel_23840\\649171342.py:20: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '<DatetimeArray>\n",
      "['2017-01-01 00:00:00', '2017-01-01 00:00:00', '2017-01-01 00:00:00', '2017-01-01 00:00:00', '2017-01-01 00:00:00', '2017-01-01 00:00:00', '2017-01-01 00:00:00', '2017-01-01 00:00:00', '2017-01-01 00:00:00', '2017-01-01 00:00:00',\n",
      " ...\n",
      " '2019-12-01 00:00:00', '2019-12-01 00:00:00', '2019-12-01 00:00:00', '2019-12-01 00:00:00', '2019-12-01 00:00:00', '2019-12-01 00:00:00', '2019-12-01 00:00:00', '2019-12-01 00:00:00', '2019-12-01 00:00:00', '2019-12-01 00:00:00']\n",
      "Length: 62257, dtype: datetime64[ns]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  filtered_data.loc[:, 'periodo'] = pd.to_datetime(filtered_data['periodo'].astype(str) + '01', format='%Y%m%d')\n"
     ]
    }
   ],
   "source": [
    "# Filtrar los datos para el período especificado\n",
    "#data['periodo'] = data['periodo'].astype(str)\n",
    "#data = data[(data['periodo'] >= '201801') & (data['periodo'] <= '201812')]\n",
    "\n",
    "# Agrupar por product_id\n",
    "#products = data['product_id'].unique()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Verificar el tipo de dato de la columna 'periodo'\n",
    "print(data['periodo'].dtype)\n",
    "\n",
    "# Obtener los 10 product_id con más ventas en todo el dataframe\n",
    "top_products = data.groupby('product_id')['tn'].sum().nlargest(10).index\n",
    "\n",
    "# Filtrar el dataframe para quedarse solo con estos productos\n",
    "filtered_data = data[data['product_id'].isin(top_products)].copy()\n",
    "\n",
    "# Convertir 'periodo' a un formato datetime\n",
    "filtered_data.loc[:, 'periodo'] = pd.to_datetime(filtered_data['periodo'].astype(str) + '01', format='%Y%m%d')\n",
    "\n",
    "# Crear características temporales adicionales si es necesario\n",
    "filtered_data.loc[:, 'month'] = filtered_data['periodo'].dt.month\n",
    "filtered_data.loc[:, 'year'] = filtered_data['periodo'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        periodo  customer_id  product_id  plan_precios_cuidados  cust_request_qty  cust_request_tn       tn  month  year\n",
      "4766 2017-01-01        10063       20007                      0                 1          0.81730  0.81730      1  2017\n",
      "4767 2017-01-01        10046       20007                      0                 1          8.17296  8.17296      1  2017\n",
      "4768 2017-01-01        10027       20007                      0                 2          0.38919  0.38919      1  2017\n",
      "4769 2017-01-01        10045       20007                      0                 1          1.63460  1.63460      1  2017\n",
      "4770 2017-01-01        10488       20007                      0                 1          0.24324  0.24324      1  2017\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 62257 entries, 4766 to 2916470\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   periodo                62257 non-null  datetime64[ns]\n",
      " 1   customer_id            62257 non-null  int64         \n",
      " 2   product_id             62257 non-null  int64         \n",
      " 3   plan_precios_cuidados  62257 non-null  int64         \n",
      " 4   cust_request_qty       62257 non-null  int64         \n",
      " 5   cust_request_tn        62257 non-null  float64       \n",
      " 6   tn                     62257 non-null  float64       \n",
      " 7   month                  62257 non-null  int32         \n",
      " 8   year                   62257 non-null  int32         \n",
      "dtypes: datetime64[ns](1), float64(2), int32(2), int64(4)\n",
      "memory usage: 4.3 MB\n"
     ]
    }
   ],
   "source": [
    "# Verificar los datos filtrados\n",
    "print(filtered_data.head())\n",
    "filtered_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 2: Entrenamiento del Modelo LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 3.25883\tvalid_1's rmse: 3.29998\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's rmse: 3.56097\tvalid_1's rmse: 3.2663\n",
      "Entrenamiento completado\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Crear las características y la variable objetivo\n",
    "X = filtered_data.drop(columns=['tn', 'periodo', 'customer_id'])\n",
    "y = filtered_data['tn']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear los datasets de LightGBM\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "\n",
    "# Definir los parámetros del modelo\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# Entrenar el modelo con devoluciones de llamada\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[train_data, val_data],\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50),\n",
    "        lgb.log_evaluation(period=100)  # Controla la frecuencia de la salida detallada\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Verificar el modelo\n",
    "print('Entrenamiento completado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 3: Predicción para Febrero de 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "LightGBMError",
     "evalue": "The number of features in data (5) is not the same as it was in training data (6).\nYou can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m feb_2020_df \u001b[38;5;241m=\u001b[39m feb_2020_df[features_used]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Realizar las predicciones\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeb_2020_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Crear el dataframe final con las predicciones\u001b[39;00m\n\u001b[0;32m     29\u001b[0m result_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m'\u001b[39m: feb_2020_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtn\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions\n\u001b[0;32m     32\u001b[0m })\n",
      "File \u001b[1;32m~\\Documents\\PERSONAL\\Maestria\\Materias\\LABO_3\\ambiente-virtual\\Lib\\site-packages\\lightgbm\\basic.py:4738\u001b[0m, in \u001b[0;36mBooster.predict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features, **kwargs)\u001b[0m\n\u001b[0;32m   4736\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4737\u001b[0m         num_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 4738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_leaf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpred_contrib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_contrib\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_has_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_has_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4747\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\PERSONAL\\Maestria\\Materias\\LABO_3\\ambiente-virtual\\Lib\\site-packages\\lightgbm\\basic.py:1183\u001b[0m, in \u001b[0;36m_InnerPredictor.predict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, validate_features)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     preds, nrow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pred_for_csc(\n\u001b[0;32m   1177\u001b[0m         csc\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m   1178\u001b[0m         start_iteration\u001b[38;5;241m=\u001b[39mstart_iteration,\n\u001b[0;32m   1179\u001b[0m         num_iteration\u001b[38;5;241m=\u001b[39mnum_iteration,\n\u001b[0;32m   1180\u001b[0m         predict_type\u001b[38;5;241m=\u001b[39mpredict_type,\n\u001b[0;32m   1181\u001b[0m     )\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m-> 1183\u001b[0m     preds, nrow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pred_for_np2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1188\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1189\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_pyarrow_table(data):\n\u001b[0;32m   1190\u001b[0m     preds, nrow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pred_for_pyarrow_table(\n\u001b[0;32m   1191\u001b[0m         table\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m   1192\u001b[0m         start_iteration\u001b[38;5;241m=\u001b[39mstart_iteration,\n\u001b[0;32m   1193\u001b[0m         num_iteration\u001b[38;5;241m=\u001b[39mnum_iteration,\n\u001b[0;32m   1194\u001b[0m         predict_type\u001b[38;5;241m=\u001b[39mpredict_type,\n\u001b[0;32m   1195\u001b[0m     )\n",
      "File \u001b[1;32m~\\Documents\\PERSONAL\\Maestria\\Materias\\LABO_3\\ambiente-virtual\\Lib\\site-packages\\lightgbm\\basic.py:1342\u001b[0m, in \u001b[0;36m_InnerPredictor.__pred_for_np2d\u001b[1;34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m preds, nrow\n\u001b[0;32m   1341\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1342\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__inner_predict_np2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_iteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredict_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1348\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\PERSONAL\\Maestria\\Materias\\LABO_3\\ambiente-virtual\\Lib\\site-packages\\lightgbm\\basic.py:1288\u001b[0m, in \u001b[0;36m_InnerPredictor.__inner_predict_np2d\u001b[1;34m(self, mat, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong length of pre-allocated predict array\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1287\u001b[0m out_num_preds \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_int64(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m-> 1288\u001b[0m \u001b[43m_safe_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterPredictForMat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1290\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mptr_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtype_ptr_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_C_API_IS_ROW_MAJOR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_iteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_iteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_c_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpred_parameter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_num_preds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPOINTER\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_double\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_preds \u001b[38;5;241m!=\u001b[39m out_num_preds\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[0;32m   1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong length for predict results\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\PERSONAL\\Maestria\\Materias\\LABO_3\\ambiente-virtual\\Lib\\site-packages\\lightgbm\\basic.py:294\u001b[0m, in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \n\u001b[0;32m    288\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    The return value from C API calls.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB\u001b[38;5;241m.\u001b[39mLGBM_GetLastError()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mLightGBMError\u001b[0m: The number of features in data (5) is not the same as it was in training data (6).\nYou can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Crear el dataframe de características agregadas por producto y mes\n",
    "agg_features = filtered_data.groupby(['product_id', 'month', 'year']).agg({\n",
    "    'plan_precios_cuidados': 'mean',\n",
    "    'cust_request_qty': 'mean',\n",
    "    'cust_request_tn': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Seleccionar las características agregadas para el último mes disponible (diciembre de 2019)\n",
    "dec_2019_features = agg_features[(agg_features['month'] == 12) & (agg_features['year'] == 2019)].copy()\n",
    "\n",
    "# Ajustar los datos para febrero de 2020\n",
    "feb_2020_df = dec_2019_features.copy()\n",
    "feb_2020_df['month'] = 2\n",
    "feb_2020_df['year'] = 2020\n",
    "\n",
    "# Seleccionar solo los top_products para la predicción\n",
    "feb_2020_df = feb_2020_df[feb_2020_df['product_id'].isin(top_products)].copy()\n",
    "\n",
    "# Asegurarse de que el DataFrame tenga las mismas columnas que las usadas en el entrenamiento\n",
    "features_used = ['plan_precios_cuidados', 'cust_request_qty', 'cust_request_tn', 'month', 'year']\n",
    "feb_2020_df = feb_2020_df[features_used]\n",
    "\n",
    "# Realizar las predicciones\n",
    "predictions = model.predict(feb_2020_df)\n",
    "\n",
    "# Crear el dataframe final con las predicciones\n",
    "result_df = pd.DataFrame({\n",
    "    'product_id': feb_2020_df['product_id'],\n",
    "    'tn': predictions\n",
    "})\n",
    "\n",
    "# Guardar las predicciones en un archivo CSV\n",
    "result_df.to_csv('predicciones_febrero_2020.csv', index=False)\n",
    "\n",
    "# Verificar el resultado\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"1.0\"></a>\n",
    "<p style=\"font-size:25px;color:#34656d;font-family:'Comic Sans MS';text-align:center;border-radius:5px;\">\n",
    "<strong>______________________</strong></p> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
