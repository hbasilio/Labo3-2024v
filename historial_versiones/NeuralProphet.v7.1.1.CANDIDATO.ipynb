{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a16e6d-d5c6-4d38-8591-dcdcde9c4674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import pandas as pd\n",
    "from neuralprophet import NeuralProphet, set_log_level\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm.notebook import tqdm\n",
    "import logging\n",
    "import warnings\n",
    "import sys\n",
    "#\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Configurar logging y warnings\n",
    "logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "warnings.filterwarnings('ignore')\n",
    "set_log_level(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b9ff21-784d-49d9-a8ab-806c0a443962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   periodo  customer_id  product_id  plan_precios_cuidados  cust_request_qty  cust_request_tn       tn\n",
      "0   201701        10234       20524                      0                 2          0.05300  0.05300\n",
      "1   201701        10032       20524                      0                 1          0.13628  0.13628\n",
      "2   201701        10217       20524                      0                 1          0.03028  0.03028\n",
      "3   201701        10125       20524                      0                 1          0.02271  0.02271\n",
      "4   201701        10012       20524                      0                11          1.54452  1.54452\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2945818 entries, 0 to 2945817\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   periodo                int64  \n",
      " 1   customer_id            int64  \n",
      " 2   product_id             int64  \n",
      " 3   plan_precios_cuidados  int64  \n",
      " 4   cust_request_qty       int64  \n",
      " 5   cust_request_tn        float64\n",
      " 6   tn                     float64\n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 157.3 MB\n",
      "   product_id\n",
      "0       20001\n",
      "1       20002\n",
      "2       20003\n",
      "3       20004\n",
      "4       20005\n",
      "    cat1      cat2         cat3   brand  sku_size  product_id        descripcion\n",
      "0  FOODS  ADEREZOS  Aji Picante  NATURA       240       20609  Salsa Aji Picante\n",
      "1  FOODS  ADEREZOS     Barbacoa  NATURA       250       20266     Salsa Barbacoa\n",
      "2  FOODS  ADEREZOS     Barbacoa  NATURA       400       20325     Salsa Barbacoa\n",
      "3  FOODS  ADEREZOS     Barbacoa  NATURA       500       20503     Salsa Barbacoa\n",
      "4  FOODS  ADEREZOS  Chimichurri  NATURA       350       20797        Chimichurri\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1251 entries, 0 to 1250\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   cat1         1251 non-null   object\n",
      " 1   cat2         1251 non-null   object\n",
      " 2   cat3         1251 non-null   object\n",
      " 3   brand        1251 non-null   object\n",
      " 4   sku_size     1251 non-null   int64 \n",
      " 5   product_id   1251 non-null   int64 \n",
      " 6   descripcion  1251 non-null   object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 68.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Lee el archivo como un DataFrame\n",
    "data_full  = pd.read_csv('data/sell-in.csv', delimiter='\\t')\n",
    "df_pid_validos  = pd.read_csv('data/productos_a_predecir.txt')\n",
    "productos_descripcion = pd.read_csv('data/tb_productos_descripcion.txt', delimiter='\\t')\n",
    "\n",
    "# Ajustar el ancho máximo de las columnas\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Ajustar el ancho máximo de la visualización\n",
    "pd.set_option('display.width', 1600)\n",
    "\n",
    "# Muestra las primeras filas del DataFrame\n",
    "print(data_full.head())\n",
    "data_full.info()\n",
    "print(df_pid_validos.head())\n",
    "print(productos_descripcion.head())\n",
    "productos_descripcion.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef2099b7-90e5-4743-8be6-afde3447a019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La lista product_ids_validos tiene 780 registros.\n"
     ]
    }
   ],
   "source": [
    "# Armado de la lista de productos validos a predecir para el periodo\n",
    "product_ids_validos = df_pid_validos['product_id'].tolist()\n",
    "\n",
    "# Ver cuántos registros tiene la lista\n",
    "num_registros = len(product_ids_validos)\n",
    "print(f\"La lista product_ids_validos tiene {num_registros} registros.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce6f4f3-f9ac-481b-b879-46509def51a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El DataFrame filtrado tiene 2293481 registros.\n",
      "Todos los product_id en el DataFrame filtrado son válidos.\n",
      "Número de registros por product_id en el DataFrame filtrado:\n",
      "product_id\n",
      "20111    7973\n",
      "20122    7950\n",
      "20120    7537\n",
      "20326    7397\n",
      "20132    7199\n",
      "         ... \n",
      "21267      67\n",
      "21252      67\n",
      "21276      64\n",
      "20886      63\n",
      "20953      62\n",
      "Name: count, Length: 780, dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2293481 entries, 0 to 2945817\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   periodo                int64  \n",
      " 1   customer_id            int64  \n",
      " 2   product_id             int64  \n",
      " 3   plan_precios_cuidados  int64  \n",
      " 4   cust_request_qty       int64  \n",
      " 5   cust_request_tn        float64\n",
      " 6   tn                     float64\n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 140.0 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>10234</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05300</td>\n",
       "      <td>0.05300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201701</td>\n",
       "      <td>10032</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13628</td>\n",
       "      <td>0.13628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201701</td>\n",
       "      <td>10217</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03028</td>\n",
       "      <td>0.03028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201701</td>\n",
       "      <td>10125</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02271</td>\n",
       "      <td>0.02271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201701</td>\n",
       "      <td>10012</td>\n",
       "      <td>20524</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1.54452</td>\n",
       "      <td>1.54452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945813</th>\n",
       "      <td>201912</td>\n",
       "      <td>10105</td>\n",
       "      <td>20853</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02230</td>\n",
       "      <td>0.02230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945814</th>\n",
       "      <td>201912</td>\n",
       "      <td>10092</td>\n",
       "      <td>20853</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00669</td>\n",
       "      <td>0.00669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945815</th>\n",
       "      <td>201912</td>\n",
       "      <td>10006</td>\n",
       "      <td>20853</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.02898</td>\n",
       "      <td>0.02898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945816</th>\n",
       "      <td>201912</td>\n",
       "      <td>10018</td>\n",
       "      <td>20853</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>0.01561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945817</th>\n",
       "      <td>201912</td>\n",
       "      <td>10020</td>\n",
       "      <td>20853</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01561</td>\n",
       "      <td>0.01561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2293481 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         periodo  customer_id  product_id  plan_precios_cuidados  cust_request_qty  cust_request_tn       tn\n",
       "0         201701        10234       20524                      0                 2          0.05300  0.05300\n",
       "1         201701        10032       20524                      0                 1          0.13628  0.13628\n",
       "2         201701        10217       20524                      0                 1          0.03028  0.03028\n",
       "3         201701        10125       20524                      0                 1          0.02271  0.02271\n",
       "4         201701        10012       20524                      0                11          1.54452  1.54452\n",
       "...          ...          ...         ...                    ...               ...              ...      ...\n",
       "2945813   201912        10105       20853                      0                 1          0.02230  0.02230\n",
       "2945814   201912        10092       20853                      0                 1          0.00669  0.00669\n",
       "2945815   201912        10006       20853                      0                 7          0.02898  0.02898\n",
       "2945816   201912        10018       20853                      0                 4          0.01561  0.01561\n",
       "2945817   201912        10020       20853                      0                 2          0.01561  0.01561\n",
       "\n",
       "[2293481 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrar el DataFrame original para quedarse solo con los product_id válidos\n",
    "filtered_data = data_full[data_full['product_id'].isin(product_ids_validos)]\n",
    "\n",
    "# Ver cuántos registros tiene el DataFrame filtrado\n",
    "num_registros_filtrados = len(filtered_data)\n",
    "print(f\"El DataFrame filtrado tiene {num_registros_filtrados} registros.\")\n",
    "\n",
    "# Verificar que todos los product_id en el DataFrame filtrado están en la lista de productos válidos\n",
    "productos_unicos_filtrados = filtered_data['product_id'].unique()\n",
    "productos_invalidos = [pid for pid in productos_unicos_filtrados if pid not in product_ids_validos]\n",
    "\n",
    "if len(productos_invalidos) == 0:\n",
    "    print(\"Todos los product_id en el DataFrame filtrado son válidos.\")\n",
    "else:\n",
    "    print(f\"Se encontraron productos no válidos en el DataFrame filtrado: {productos_invalidos}\")\n",
    "\n",
    "# (Opcional) Ver cuántos registros hay por cada product_id\n",
    "registros_por_producto = filtered_data['product_id'].value_counts()\n",
    "print(\"Número de registros por product_id en el DataFrame filtrado:\")\n",
    "print(registros_por_producto)\n",
    "\n",
    "# Ver como esta el data frame\n",
    "filtered_data.info()\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfc2fb9c-df25-4751-9e7e-23da99a09348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información de filtered_data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2293481 entries, 0 to 2945817\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   periodo                int64  \n",
      " 1   customer_id            int64  \n",
      " 2   product_id             int64  \n",
      " 3   plan_precios_cuidados  int64  \n",
      " 4   cust_request_qty       int64  \n",
      " 5   cust_request_tn        float64\n",
      " 6   tn                     float64\n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 140.0 MB\n",
      "None\n",
      "\n",
      "Información de productos_descripcion:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1251 entries, 0 to 1250\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   cat1         1251 non-null   object\n",
      " 1   cat2         1251 non-null   object\n",
      " 2   cat3         1251 non-null   object\n",
      " 3   brand        1251 non-null   object\n",
      " 4   sku_size     1251 non-null   int64 \n",
      " 5   product_id   1251 non-null   int64 \n",
      " 6   descripcion  1251 non-null   object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 68.5+ KB\n",
      "None\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['dia_semana'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 52\u001b[0m\n\u001b[0;32m     45\u001b[0m regresores \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdia_semana\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrimestre\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat1_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat2_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat3_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrand_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_tn_por_producto\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_qty_por_cliente\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mratio_tn_qty\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_precios_cuidados\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msku_size_numeric\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msku_size_category_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     49\u001b[0m ]\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# 6. Preparación del dataframe final para NeuralProphet\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m df_final \u001b[38;5;241m=\u001b[39m \u001b[43mdf_merged\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mperiodo\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mregresores\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperiodo\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mds\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtn\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# 7. Guardado del dataframe final\u001b[39;00m\n\u001b[0;32m     55\u001b[0m df_final\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_final_para_neuralprophet.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Documents\\PERSONAL\\Maestria\\Materias\\LABO_3\\ambiente-virtual\\Lib\\site-packages\\pandas\\core\\frame.py:3899\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3898\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3899\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3901\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\Documents\\PERSONAL\\Maestria\\Materias\\LABO_3\\ambiente-virtual\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\PERSONAL\\Maestria\\Materias\\LABO_3\\ambiente-virtual\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6179\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['dia_semana'] not in index\""
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Exploración inicial de los datos\n",
    "print(\"Información de filtered_data:\")\n",
    "print(filtered_data.info())\n",
    "print(\"\\nInformación de productos_descripcion:\")\n",
    "print(productos_descripcion.info())\n",
    "\n",
    "# 3. Fusión de los dataframes\n",
    "df_merged = pd.merge(filtered_data, productos_descripcion, on='product_id', how='left')\n",
    "\n",
    "# 4. Feature Engineering\n",
    "\n",
    "# 4.1 Características temporales\n",
    "df_merged['periodo'] = pd.to_datetime(df_merged['periodo'])\n",
    "df_merged['mes'] = df_merged['periodo'].dt.month\n",
    "df_merged['trimestre'] = df_merged['periodo'].dt.quarter\n",
    "\n",
    "# 4.2 Codificación de variables categóricas\n",
    "le = LabelEncoder()\n",
    "df_merged['cat1_encoded'] = le.fit_transform(df_merged['cat1'])\n",
    "df_merged['cat2_encoded'] = le.fit_transform(df_merged['cat2'])\n",
    "df_merged['cat3_encoded'] = le.fit_transform(df_merged['cat3'])\n",
    "df_merged['brand_encoded'] = le.fit_transform(df_merged['brand'])\n",
    "\n",
    "# 4.3 Características basadas en agrupaciones\n",
    "df_merged['avg_tn_por_producto'] = df_merged.groupby('product_id')['tn'].transform('mean')\n",
    "df_merged['avg_qty_por_cliente'] = df_merged.groupby('customer_id')['cust_request_qty'].transform('mean')\n",
    "\n",
    "# 4.4 Ratios y proporciones\n",
    "df_merged['ratio_tn_qty'] = df_merged['tn'] / df_merged['cust_request_qty']\n",
    "\n",
    "# 4.5 Flags binarios\n",
    "df_merged['is_precios_cuidados'] = df_merged['plan_precios_cuidados'].map({'Si': 1, 'No': 0})\n",
    "\n",
    "# 4.6 Uso directo del tamaño del SKU\n",
    "df_merged['sku_size_numeric'] = df_merged['sku_size'].fillna(0).astype(float)\n",
    "\n",
    "# 4.7 Categorización del tamaño del SKU\n",
    "df_merged['sku_size_category'] = pd.cut(df_merged['sku_size'], \n",
    "                                        bins=[0, 100, 250, 500, 1000, float('inf')],\n",
    "                                        labels=['Muy pequeño', 'Pequeño', 'Mediano', 'Grande', 'Muy grande'])\n",
    "\n",
    "df_merged['sku_size_category_encoded'] = le.fit_transform(df_merged['sku_size_category'])\n",
    "\n",
    "# 5. Selección de variables para NeuralProphet\n",
    "regresores = [\n",
    "    'mes', 'dia_semana', 'trimestre', 'cat1_encoded', 'cat2_encoded', 'cat3_encoded',\n",
    "    'brand_encoded', 'avg_tn_por_producto', 'avg_qty_por_cliente', 'ratio_tn_qty',\n",
    "    'is_precios_cuidados', 'sku_size_numeric', 'sku_size_category_encoded'\n",
    "]\n",
    "\n",
    "# 6. Preparación del dataframe final para NeuralProphet\n",
    "df_final = df_merged[['periodo', 'tn'] + regresores].rename(columns={'periodo': 'ds', 'tn': 'y'})\n",
    "\n",
    "# 7. Guardado del dataframe final\n",
    "df_final.to_csv('df_final_para_neuralprophet.csv', index=False)\n",
    "\n",
    "print(\"Dataframe final guardado con éxito. Listo para ser utilizado en NeuralProphet.\")\n",
    "\n",
    "# 8. Resumen de las nuevas características\n",
    "print(\"\\nResumen de las nuevas características:\")\n",
    "for column in regresores:\n",
    "    if df_final[column].dtype == 'object':\n",
    "        print(f\"\\n{column}:\")\n",
    "        print(df_final[column].value_counts())\n",
    "    else:\n",
    "        print(f\"\\n{column}:\")\n",
    "        print(df_final[column].describe())\n",
    "\n",
    "# 9. Verificación de valores nulos\n",
    "print(\"\\nVerificación de valores nulos:\")\n",
    "print(df_final.isnull().sum())\n",
    "\n",
    "# 10. Correlaciones entre las variables\n",
    "print(\"\\nCorrelaciones entre las variables:\")\n",
    "correlation_matrix = df_final[['y'] + regresores].corr()\n",
    "print(correlation_matrix['y'].sort_values(ascending=False))\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c011c0b-0f27-4b83-9303-26bf61c6be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular diferentes customer_id y product_id\n",
    "num_customers = filtered_data['customer_id'].nunique()\n",
    "num_products = filtered_data['product_id'].nunique()\n",
    "\n",
    "print(f'Número de diferentes customer_id: {num_customers}')\n",
    "print(f'Número de diferentes product_id: {num_products}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c9ff40-d1f4-40c7-a337-4addf4be2eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un listado por período, customer_id y product_id\n",
    "listado = filtered_data.groupby(['periodo', 'customer_id', 'product_id']).size().reset_index(name='num_pedidos')\n",
    "\n",
    "# Ordenar por período y customer_id\n",
    "listado_ordenado = listado.sort_values(by=['periodo', 'customer_id'])\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(listado_ordenado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57b48e8-c26b-4408-9342-57c8be08c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los registros donde num_pedidos sea mayor que 1\n",
    "registros_multiples_pedidos = listado_ordenado[listado_ordenado['num_pedidos'] > 1]\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(registros_multiples_pedidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f84602-54c8-44d8-8232-49b6bdc4a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un listado por período y product_id sumando todos los clientes\n",
    "listado_productos_periodos = filtered_data.groupby(['periodo', 'product_id']).size().reset_index(name='num_pedidos')\n",
    "\n",
    "# Contar el total de periodos para cada product_id\n",
    "total_periodos_por_producto = listado_productos_periodos.groupby('product_id')['periodo'].nunique().reset_index(name='total_periodos')\n",
    "\n",
    "# Ordenar por total de periodos en orden descendente\n",
    "total_periodos_por_producto_ordenado = total_periodos_por_producto.sort_values(by='total_periodos', ascending=False)\n",
    "\n",
    "# Configurar pandas para mostrar todas las filas y columnas\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Mostrar el resultado completo\n",
    "#print(total_periodos_por_producto_ordenado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa6b13-91a1-45bc-9890-3e4bc0fb7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que la columna 'periodo' esté en formato de fecha\n",
    "filtered_data['periodo'] = pd.to_datetime(filtered_data['periodo'], format='%Y%m')\n",
    "\n",
    "# Agrupar por período y sumar la cantidad de ventas en toneladas\n",
    "ventas_por_periodo = filtered_data.groupby(filtered_data['periodo'].dt.to_period('M'))['tn'].sum().reset_index(name='total_toneladas')\n",
    "\n",
    "# Convertir la columna 'periodo' de nuevo a formato de fecha\n",
    "ventas_por_periodo['periodo'] = ventas_por_periodo['periodo'].dt.to_timestamp()\n",
    "\n",
    "# Crear el gráfico de barras en color verde\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(ventas_por_periodo['periodo'], ventas_por_periodo['total_toneladas'], color='green', width=20)  # Ajusta el ancho de las barras\n",
    "\n",
    "# Agregar títulos y etiquetas\n",
    "plt.title('Cantidad de ventas en toneladas por período')\n",
    "plt.xlabel('Período')\n",
    "plt.ylabel('Total de toneladas vendidas')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar el listado de los periodos con las toneladas vendidas\n",
    "print(ventas_por_periodo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5385bb-0584-489a-a945-d515d660e0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que la columna 'periodo' esté en formato de fecha\n",
    "filtered_data['periodo'] = pd.to_datetime(filtered_data['periodo'], format='%Y%m')\n",
    "\n",
    "# Agrupar por período y contar la cantidad de productos vendidos en cada mes\n",
    "ventas_por_mes = filtered_data.groupby(filtered_data['periodo'].dt.to_period('M')).size().reset_index(name='cantidad_productos')\n",
    "\n",
    "# Convertir la columna 'periodo' de nuevo a formato de fecha\n",
    "ventas_por_mes['periodo'] = ventas_por_mes['periodo'].dt.to_timestamp()\n",
    "\n",
    "# Crear el gráfico\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(ventas_por_mes['periodo'], ventas_por_mes['cantidad_productos'], marker='o', linestyle='-', color='b')\n",
    "\n",
    "# Agregar títulos y etiquetas\n",
    "plt.title('Cantidad de productos vendidos por mes')\n",
    "plt.xlabel('Mes')\n",
    "plt.ylabel('Cantidad de productos vendidos')\n",
    "plt.grid(True)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c651ce7-42ce-41c9-9243-4be86729eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que la columna 'periodo' esté en formato de fecha\n",
    "filtered_data['periodo'] = pd.to_datetime(filtered_data['periodo'], format='%Y%m')\n",
    "\n",
    "# Agrupar por período y contar la cantidad de distintos productos vendidos en cada período\n",
    "productos_por_periodo = filtered_data.groupby(filtered_data['periodo'].dt.to_period('M'))['product_id'].nunique().reset_index(name='cantidad_productos')\n",
    "\n",
    "# Convertir la columna 'periodo' de nuevo a formato de fecha\n",
    "productos_por_periodo['periodo'] = productos_por_periodo['periodo'].dt.to_timestamp()\n",
    "\n",
    "# Crear el gráfico de barras con barras más gruesas\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(productos_por_periodo['periodo'], productos_por_periodo['cantidad_productos'], color='skyblue', width=20)  # Ajusta el ancho de las barras\n",
    "\n",
    "# Agregar títulos y etiquetas\n",
    "plt.title('Cantidad de distintos productos vendidos por período')\n",
    "plt.xlabel('Período')\n",
    "plt.ylabel('Cantidad de distintos productos vendidos')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar el listado de los 36 meses con los resultados de diferentes productos vendidos\n",
    "print(productos_por_periodo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42774984-6daf-4352-9d63-1008ed442720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Version 7.1.1\n",
    "#  Se agrega separan los productos que tienen mas de 20 meses de historia para ser tratados diferente en el algoritmo\n",
    "#\n",
    "# Función para filtrar datos por rango de product_id\n",
    "def filtrar_por_producto(df, producto_inicio, producto_fin):\n",
    "    return df[(df['product_id'] >= producto_inicio) & (df['product_id'] <= producto_fin)]\n",
    "\n",
    "# Función para preparar datos para NeuralProphet\n",
    "def preparar_datos(df):\n",
    "    df = df.groupby(['periodo', 'product_id']).agg({'tn': 'sum'}).reset_index()\n",
    "    df['ds'] = pd.to_datetime(df['periodo'], format='%Y%m')\n",
    "    df.rename(columns={'tn': 'y'}, inplace=True)\n",
    "    return df[['ds', 'y', 'product_id']]\n",
    "\n",
    "# Filtrado de datos para el rango de productos deseado\n",
    "producto_inicio = 20001\n",
    "producto_fin = 20012\n",
    "#producto_fin = 21276\n",
    "datos_filtrados = filtrar_por_producto(filtered_data, producto_inicio, producto_fin)\n",
    "\n",
    "# Preparación de datos para NeuralProphet\n",
    "datos = preparar_datos(datos_filtrados)\n",
    "datos.head()\n",
    "datos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fd985b-99ff-4a17-bba5-248a6ee079e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nos aseguramos de tener registros en cero para productos que pudieron no haber tenido ventas en un periodo a pesar de seguir estando en stock\n",
    "\n",
    "# Asegurémonos de que los datos estén ordenados por product_id y ds\n",
    "datos['ds'] = pd.to_datetime(datos['ds'])\n",
    "datos.sort_values(by=['product_id', 'ds'], inplace=True)\n",
    "\n",
    "# Crear una función para agregar registros en cero\n",
    "def agregar_registros_cero(df):\n",
    "    df_list = []\n",
    "    for producto, datos_producto in df.groupby('product_id'):\n",
    "        # Obtener el rango de fechas completo para el producto\n",
    "        fecha_inicio = datos_producto['ds'].min()\n",
    "        fecha_fin = datos_producto['ds'].max()\n",
    "        rango_fechas = pd.date_range(start=fecha_inicio, end=fecha_fin, freq='MS')  # Frecuencia mensual\n",
    "\n",
    "        # Completar el dataframe con fechas faltantes y valores en cero\n",
    "        datos_completos = pd.DataFrame(rango_fechas, columns=['ds'])\n",
    "        datos_completos['product_id'] = producto\n",
    "        datos_completos = datos_completos.merge(datos_producto, on=['ds', 'product_id'], how='left')\n",
    "        datos_completos['y'].fillna(0, inplace=True)  # Llenar NaNs con ceros\n",
    "\n",
    "        df_list.append(datos_completos)\n",
    "\n",
    "    return pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Mostrar cantidad de registros antes de agregar ceros\n",
    "print(f\"Cantidad de registros antes de agregar ceros: {len(datos)}\")\n",
    "\n",
    "# Aplicar la función para agregar registros en cero\n",
    "datos_completos_cero = agregar_registros_cero(datos)\n",
    "\n",
    "# Mostrar cantidad de registros después de agregar ceros\n",
    "print(f\"Cantidad de registros después de agregar ceros: {len(datos_completos_cero)}\")\n",
    "\n",
    "# Mostrar los primeros registros del dataframe resultante\n",
    "print(\"\\nPrimeros registros del dataframe resultante:\")\n",
    "print(datos_completos_cero.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2178b16a-dbe4-40fa-989e-0cb95f005722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero, veamos qué columnas tienes en tu DataFrame\n",
    "print(\"Columnas en el DataFrame:\")\n",
    "print(datos.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87467636-a977-4925-b63b-41fc8a849503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos los modelos que tienen mas de 15 periodos en el data frame\n",
    "#\n",
    "# Suponemos que 'datos' ya está preparado y contiene las columnas ['ds', 'y', 'product_id']\n",
    "datos['ds'] = pd.to_datetime(datos['ds'])\n",
    "datos.sort_values(by=['product_id', 'ds'], inplace=True)\n",
    "\n",
    "# Dividir los datos en train, validation y test\n",
    "train_df = datos_completos_cero[datos_completos_cero['ds'] < '2019-11-01']\n",
    "val_df = datos_completos_cero[datos_completos_cero['ds'] == '2019-11-01']\n",
    "test_df = datos_completos_cero[datos_completos_cero['ds'] == '2019-12-01']\n",
    "\n",
    "# Filtrar productos con más de 15 periodos de historia\n",
    "productos_mas_historia = datos_completos_cero['product_id'].value_counts()[datos_completos_cero['product_id'].value_counts() > 15].index.tolist()\n",
    "print(f\"Número de productos con más de 15 periodos de historia: {len(productos_mas_historia)}\")\n",
    "\n",
    "def entrenar_y_predecir(train_df, val_df, test_df):\n",
    "    modelos = {}\n",
    "    predicciones = pd.DataFrame()\n",
    "    for producto in tqdm(productos_mas_historia, desc=\"Procesando productos\"):\n",
    "        df_producto_train = train_df[train_df['product_id'] == producto][['ds', 'y']]\n",
    "        df_producto_val = val_df[val_df['product_id'] == producto][['ds', 'y']]\n",
    "        df_producto_test = test_df[test_df['product_id'] == producto][['ds', 'y']]\n",
    "        \n",
    "        m = NeuralProphet(\n",
    "            n_forecasts=2,\n",
    "            yearly_seasonality=True,\n",
    "            batch_size=12,\n",
    "            epochs=1000,\n",
    "            learning_rate=0.025,\n",
    "            loss_func='Huber',\n",
    "            daily_seasonality=False,\n",
    "            weekly_seasonality=False,\n",
    "            seasonality_mode='multiplicative',\n",
    "            lagged_reg_layers=[16, 8],  # Ajustar las capas ocultas\n",
    "            normalize=\"standardize\"\n",
    "        )\n",
    "        \n",
    "        # Combinar train y validation para el entrenamiento final\n",
    "        df_producto_train_val = pd.concat([df_producto_train, df_producto_val])\n",
    "        \n",
    "        m.fit(df_producto_train, validation_df=df_producto_val, freq='M')\n",
    "        \n",
    "        # Crear future dataframe manualmente\n",
    "        last_date = df_producto_test['ds'].max()\n",
    "        future_dates = pd.date_range(start=last_date, periods=3, freq='MS')[1:]  # Dos meses adelante\n",
    "        future = pd.DataFrame({'ds': future_dates, 'y': [None]*len(future_dates)})\n",
    "        \n",
    "        forecast = m.predict(future)\n",
    "        \n",
    "        forecast.loc[forecast['yhat1'] < 0, 'yhat1'] = 0  # Convertir valores negativos a cero\n",
    "        pred_febrero_2020 = forecast[forecast['ds'] == pd.Timestamp('2020-02-01')][['ds', 'yhat1']]\n",
    "        pred_febrero_2020['product_id'] = producto\n",
    "        predicciones = pd.concat([predicciones, pred_febrero_2020[['ds', 'yhat1', 'product_id']]])\n",
    "        modelos[producto] = m\n",
    "    return predicciones, modelos\n",
    "\n",
    "# Entrenar el modelo y obtener predicciones\n",
    "predicciones_febrero_2020, modelos = entrenar_y_predecir(train_df, val_df, test_df)\n",
    "\n",
    "# Renombrar las columnas para el archivo de salida\n",
    "predicciones_febrero_2020.rename(columns={'yhat1': 'tn'}, inplace=True)\n",
    "\n",
    "# Convertir la columna 'ds' al formato YYYYMM\n",
    "predicciones_febrero_2020['ds'] = predicciones_febrero_2020['ds'].dt.strftime('%Y%m')\n",
    "\n",
    "# Guardar el resultado en un archivo .csv solo con la predicción para febrero 2020\n",
    "predicciones_febrero_2020.to_csv('NeuralProphet_mas_20_periodos.v7.1.1.csv', index=False)\n",
    "\n",
    "# Mostrar un resumen del resultado\n",
    "print(f\"Número total de predicciones: {len(predicciones_febrero_2020)}\")\n",
    "print(predicciones_febrero_2020.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c9f30-63a2-4568-b58d-b73800401439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suponemos que 'datos' ya está preparado y contiene las columnas ['ds', 'y', 'product_id']\n",
    "datos['ds'] = pd.to_datetime(datos['ds'])\n",
    "datos.sort_values(by=['product_id', 'ds'], inplace=True)\n",
    "\n",
    "# Dividir los datos en train y test\n",
    "train_df = datos_completos_cero[datos_completos_cero['ds'] < '2019-12-01']\n",
    "test_df = datos_completos_cero[datos_completos_cero['ds'] == '2019-12-01']\n",
    "\n",
    "# Filtrar productos con menos o igual a 15 periodos de historia\n",
    "productos_menos_historia = datos_completos_cero['product_id'].value_counts()[datos_completos_cero['product_id'].value_counts() <= 15].index.tolist()\n",
    "print(f\"Número de productos con menos o igual a 15 periodos de historia: {len(productos_menos_historia)}\")\n",
    "\n",
    "def entrenar_y_predecir_menos_historia(train_df, test_df):\n",
    "    modelos = {}\n",
    "    predicciones = pd.DataFrame()\n",
    "    for producto in tqdm(productos_menos_historia, desc=\"Procesando productos\"):\n",
    "        df_producto_train = train_df[train_df['product_id'] == producto][['ds', 'y']]\n",
    "        df_producto_test = test_df[test_df['product_id'] == producto][['ds', 'y']]\n",
    "        \n",
    "        if len(df_producto_train) < 5:\n",
    "            promedio = df_producto_train['y'].mean()\n",
    "            pred_febrero_2020 = pd.DataFrame({\n",
    "                'ds': [pd.Timestamp('2020-02-01')],\n",
    "                'yhat1': [promedio],\n",
    "                'product_id': [producto]\n",
    "            })\n",
    "            predicciones = pd.concat([predicciones, pred_febrero_2020])\n",
    "        else:\n",
    "            m = NeuralProphet(\n",
    "                n_forecasts=2,\n",
    "                yearly_seasonality=True,\n",
    "                batch_size=6,\n",
    "                epochs=1000,\n",
    "                learning_rate=0.025,\n",
    "                loss_func='Huber',\n",
    "                daily_seasonality=False,\n",
    "                weekly_seasonality=False,\n",
    "                seasonality_mode='multiplicative',\n",
    "                lagged_reg_layers=[16, 8],  # Ajustar las capas ocultas\n",
    "                normalize=\"standardize\",\n",
    "            )\n",
    "            \n",
    "            m.fit(df_producto_train, freq='M')\n",
    "            \n",
    "            last_date = df_producto_test['ds'].max()\n",
    "            future_dates = pd.date_range(start=last_date, periods=3, freq='MS')[1:]\n",
    "            future = pd.DataFrame({'ds': future_dates, 'y': [None]*len(future_dates)})\n",
    "            \n",
    "            forecast = m.predict(future)\n",
    "            \n",
    "            forecast.loc[forecast['yhat1'] < 0, 'yhat1'] = 0\n",
    "            pred_febrero_2020 = forecast[forecast['ds'] == pd.Timestamp('2020-02-01')][['ds', 'yhat1']]\n",
    "            pred_febrero_2020['product_id'] = producto\n",
    "            predicciones = pd.concat([predicciones, pred_febrero_2020[['ds', 'yhat1', 'product_id']]])\n",
    "            modelos[producto] = m\n",
    "    \n",
    "    return predicciones, modelos\n",
    "\n",
    "# Entrenar el modelo y obtener predicciones\n",
    "predicciones_febrero_2020, modelos = entrenar_y_predecir_menos_historia(train_df, test_df)\n",
    "\n",
    "# Verificar si se generaron predicciones\n",
    "if predicciones_febrero_2020.empty:\n",
    "    print(\"No se generaron predicciones. Verifica los datos de entrada.\")\n",
    "else:\n",
    "    print(f\"Número total de predicciones: {len(predicciones_febrero_2020)}\")\n",
    "    \n",
    "    # Renombrar las columnas para el archivo de salida\n",
    "    if 'yhat1' in predicciones_febrero_2020.columns:\n",
    "        predicciones_febrero_2020.rename(columns={'yhat1': 'tn'}, inplace=True)\n",
    "    \n",
    "    # Convertir la columna 'ds' al formato YYYYMM si existe\n",
    "    if 'ds' in predicciones_febrero_2020.columns:\n",
    "        predicciones_febrero_2020['ds'] = pd.to_datetime(predicciones_febrero_2020['ds']).dt.strftime('%Y%m')\n",
    "    \n",
    "    # Guardar el resultado en un archivo .csv solo con la predicción para febrero 2020\n",
    "    predicciones_febrero_2020.to_csv('NeuralProphet_menos_20_periodos.v7.1.1.csv', index=False)\n",
    "    \n",
    "    # Mostrar un resumen del resultado\n",
    "    print(predicciones_febrero_2020.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06033363-9703-4012-b181-4d895cb28405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer los archivos CSV\n",
    "df_menos = pd.read_csv('NeuralProphet_menos_20_periodos.v7.1.1.csv')\n",
    "df_mas = pd.read_csv('NeuralProphet_mas_20_periodos.v7.1.1.csv')\n",
    "\n",
    "# Combinar los dos DataFrames\n",
    "df_combinado = pd.concat([df_menos, df_mas])\n",
    "\n",
    "# Ordenar por product_id\n",
    "df_combinado = df_combinado.sort_values('product_id')\n",
    "\n",
    "# Seleccionar solo las columnas 'product_id' y 'tn'\n",
    "df_final = df_combinado[['product_id', 'tn']]\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo CSV\n",
    "df_final.to_csv('NeuralProphet.v7.1.1.CAN.paraKaggle.csv', index=False)\n",
    "\n",
    "print(\"Archivo combinado creado con éxito.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323219d6-f220-4783-bfcd-6c5a5dd154b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo CSV\n",
    "df = pd.read_csv('NeuralProphet.v7.1.1.CAN.paraKaggle.csv')\n",
    "\n",
    "# Calcular la suma total actual de 'tn'\n",
    "suma_actual = df['tn'].sum()\n",
    "print(f\"Suma total de 'tn': {suma_actual:.2f}\")\n",
    "\n",
    "# Calcular el factor de ajuste\n",
    "factor_ajuste = 30600 / suma_actual\n",
    "\n",
    "# Ajustar los valores de 'tn'\n",
    "df['tn'] = df['tn'] * factor_ajuste\n",
    "\n",
    "# Verificar que la nueva suma sea 30600\n",
    "nueva_suma = df['tn'].sum()\n",
    "print(f\"Nueva suma total de 'tn': {nueva_suma:.2f}\")\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo CSV\n",
    "df.to_csv('NeuralProphet.v7.1.1.CAN.paraKaggle_ajustado.csv', index=False)\n",
    "\n",
    "print(\"Archivo ajustado creado con éxito.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6930039c-0126-4cd7-8ef2-3c72db8b5c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
